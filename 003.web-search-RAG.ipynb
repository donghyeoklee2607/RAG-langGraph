{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a1293b5",
   "metadata": {},
   "source": [
    "# 003. Web Search Rag with LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b985c71",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab85c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from tools import logging\n",
    "import nest_asyncio\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "logging.langsmith(\"web-search-RAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31194296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.3.21 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.3.21)\n",
      "Requirement already satisfied: langchain-core==0.3.46 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (0.3.46)\n",
      "Requirement already satisfied: langchain-community==0.3.20 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (0.3.20)\n",
      "Requirement already satisfied: langchain-openai==0.3.9 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (0.3.9)\n",
      "Requirement already satisfied: langgraph==0.3.18 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (0.3.18)\n",
      "Requirement already satisfied: langsmith==0.3.18 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (0.3.18)\n",
      "Requirement already satisfied: langchain-text-splitters==0.3.7 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (0.3.7)\n",
      "Requirement already satisfied: langchain-teddynote==0.3.44 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (0.3.44)\n",
      "Requirement already satisfied: openai==1.67.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (1.67.0)\n",
      "Requirement already satisfied: tiktoken==0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (0.9.0)\n",
      "Requirement already satisfied: faiss-cpu==1.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (1.10.0)\n",
      "Requirement already satisfied: rank-bm25==0.2.2 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (0.2.2)\n",
      "Requirement already satisfied: flashrank==0.2.10 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (0.2.10)\n",
      "Requirement already satisfied: llama-index-core==0.11.23 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 21)) (0.11.23)\n",
      "Requirement already satisfied: llama-parse==0.6.4.post1 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 22)) (0.6.4.post1)\n",
      "Requirement already satisfied: llama-index-readers-file==0.2.2 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 23)) (0.2.2)\n",
      "Requirement already satisfied: pymupdf==1.25.4 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 24)) (1.25.4)\n",
      "Requirement already satisfied: google-search-results==2.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 27)) (2.4.2)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 30)) (1.0.1)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 31)) (1.6.0)\n",
      "Requirement already satisfied: pydantic==2.10.6 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 32)) (2.10.6)\n",
      "Requirement already satisfied: grandalf==0.8 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 35)) (0.8)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain==0.3.21->-r requirements.txt (line 2)) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain==0.3.21->-r requirements.txt (line 2)) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain==0.3.21->-r requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core==0.3.46->-r requirements.txt (line 3)) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core==0.3.46->-r requirements.txt (line 3)) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core==0.3.46->-r requirements.txt (line 3)) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core==0.3.46->-r requirements.txt (line 3)) (4.15.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community==0.3.20->-r requirements.txt (line 4)) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community==0.3.20->-r requirements.txt (line 4)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community==0.3.20->-r requirements.txt (line 4)) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community==0.3.20->-r requirements.txt (line 4)) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community==0.3.20->-r requirements.txt (line 4)) (1.26.4)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph==0.3.18->-r requirements.txt (line 6)) (2.1.2)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph==0.3.18->-r requirements.txt (line 6)) (0.1.8)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph==0.3.18->-r requirements.txt (line 6)) (0.1.74)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith==0.3.18->-r requirements.txt (line 7)) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith==0.3.18->-r requirements.txt (line 7)) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith==0.3.18->-r requirements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith==0.3.18->-r requirements.txt (line 7)) (0.23.0)\n",
      "Requirement already satisfied: kiwipiepy in /opt/anaconda3/lib/python3.12/site-packages (from langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (0.20.4)\n",
      "Requirement already satisfied: pinecone-client[grpc] in /opt/anaconda3/lib/python3.12/site-packages (from langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (3.2.2)\n",
      "Requirement already satisfied: pinecone-text in /opt/anaconda3/lib/python3.12/site-packages (from langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (0.11.0)\n",
      "Requirement already satisfied: olefile in /opt/anaconda3/lib/python3.12/site-packages (from langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (0.47)\n",
      "Requirement already satisfied: pdf2image in /opt/anaconda3/lib/python3.12/site-packages (from langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (1.17.0)\n",
      "Requirement already satisfied: anthropic in /opt/anaconda3/lib/python3.12/site-packages (from langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (0.75.0)\n",
      "Requirement already satisfied: deepl in /opt/anaconda3/lib/python3.12/site-packages (from langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (1.21.1)\n",
      "Requirement already satisfied: feedparser in /opt/anaconda3/lib/python3.12/site-packages (from langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (6.0.12)\n",
      "Requirement already satisfied: tavily-python in /opt/anaconda3/lib/python3.12/site-packages (from langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (0.7.13)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (2.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai==1.67.0->-r requirements.txt (line 12)) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai==1.67.0->-r requirements.txt (line 12)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from openai==1.67.0->-r requirements.txt (line 12)) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from openai==1.67.0->-r requirements.txt (line 12)) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.12/site-packages (from openai==1.67.0->-r requirements.txt (line 12)) (4.66.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.12/site-packages (from tiktoken==0.9.0->-r requirements.txt (line 13)) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers in /opt/anaconda3/lib/python3.12/site-packages (from flashrank==0.2.10->-r requirements.txt (line 18)) (0.21.4)\n",
      "Requirement already satisfied: onnxruntime in /opt/anaconda3/lib/python3.12/site-packages (from flashrank==0.2.10->-r requirements.txt (line 18)) (1.23.2)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/anaconda3/lib/python3.12/site-packages (from llama-index-core==0.11.23->-r requirements.txt (line 21)) (1.3.1)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/anaconda3/lib/python3.12/site-packages (from llama-index-core==0.11.23->-r requirements.txt (line 21)) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from llama-index-core==0.11.23->-r requirements.txt (line 21)) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from llama-index-core==0.11.23->-r requirements.txt (line 21)) (2024.6.1)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/anaconda3/lib/python3.12/site-packages (from llama-index-core==0.11.23->-r requirements.txt (line 21)) (3.3)\n",
      "Requirement already satisfied: nltk>3.8.1 in /opt/anaconda3/lib/python3.12/site-packages (from llama-index-core==0.11.23->-r requirements.txt (line 21)) (3.9.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from llama-index-core==0.11.23->-r requirements.txt (line 21)) (10.4.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from llama-index-core==0.11.23->-r requirements.txt (line 21)) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/lib/python3.12/site-packages (from llama-index-core==0.11.23->-r requirements.txt (line 21)) (1.14.1)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.4 in /opt/anaconda3/lib/python3.12/site-packages (from llama-parse==0.6.4.post1->-r requirements.txt (line 22)) (0.6.21)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/anaconda3/lib/python3.12/site-packages (from llama-index-readers-file==0.2.2->-r requirements.txt (line 23)) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from llama-index-readers-file==0.2.2->-r requirements.txt (line 23)) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /opt/anaconda3/lib/python3.12/site-packages (from llama-index-readers-file==0.2.2->-r requirements.txt (line 23)) (0.0.26)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic==2.10.6->-r requirements.txt (line 32)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic==2.10.6->-r requirements.txt (line 32)) (2.27.2)\n",
      "Requirement already satisfied: pyparsing in /opt/anaconda3/lib/python3.12/site-packages (from grandalf==0.8->-r requirements.txt (line 35)) (3.1.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.20->-r requirements.txt (line 4)) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.20->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.20->-r requirements.txt (line 4)) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.20->-r requirements.txt (line 4)) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.20->-r requirements.txt (line 4)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.20->-r requirements.txt (line 4)) (1.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai==1.67.0->-r requirements.txt (line 12)) (3.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file==0.2.2->-r requirements.txt (line 23)) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.20->-r requirements.txt (line 4)) (3.26.1)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith==0.3.18->-r requirements.txt (line 7)) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith==0.3.18->-r requirements.txt (line 7)) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith==0.3.18->-r requirements.txt (line 7)) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.46->-r requirements.txt (line 3)) (2.1)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph==0.3.18->-r requirements.txt (line 6)) (1.12.0)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /opt/anaconda3/lib/python3.12/site-packages (from llama-cloud-services>=0.6.4->llama-parse==0.6.4.post1->-r requirements.txt (line 22)) (8.1.7)\n",
      "Requirement already satisfied: llama-cloud==0.1.19 in /opt/anaconda3/lib/python3.12/site-packages (from llama-cloud-services>=0.6.4->llama-parse==0.6.4.post1->-r requirements.txt (line 22)) (0.1.19)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=4.3.7 in /opt/anaconda3/lib/python3.12/site-packages (from llama-cloud-services>=0.6.4->llama-parse==0.6.4.post1->-r requirements.txt (line 22)) (4.5.1)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core==0.11.23->-r requirements.txt (line 21)) (1.4.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.20->-r requirements.txt (line 4)) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.21->-r requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.21->-r requirements.txt (line 2)) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.11.23->-r requirements.txt (line 21)) (3.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core==0.11.23->-r requirements.txt (line 21)) (1.0.0)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.15 in /opt/anaconda3/lib/python3.12/site-packages (from anthropic->langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (0.17.0)\n",
      "Requirement already satisfied: sgmllib3k in /opt/anaconda3/lib/python3.12/site-packages (from feedparser->langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (1.0.0)\n",
      "Requirement already satisfied: kiwipiepy_model<0.21,>=0.20 in /opt/anaconda3/lib/python3.12/site-packages (from kiwipiepy->langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (0.20.0)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime->flashrank==0.2.10->-r requirements.txt (line 18)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime->flashrank==0.2.10->-r requirements.txt (line 18)) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime->flashrank==0.2.10->-r requirements.txt (line 18)) (6.33.2)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime->flashrank==0.2.10->-r requirements.txt (line 18)) (1.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (2023.3)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.53.0 in /opt/anaconda3/lib/python3.12/site-packages (from pinecone-client[grpc]->langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (1.72.0)\n",
      "Requirement already satisfied: grpc-gateway-protoc-gen-openapiv2==0.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from pinecone-client[grpc]->langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (0.1.0)\n",
      "Requirement already satisfied: grpcio>=1.59.0 in /opt/anaconda3/lib/python3.12/site-packages (from pinecone-client[grpc]->langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (1.67.1)\n",
      "Requirement already satisfied: lz4>=3.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from pinecone-client[grpc]->langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (4.3.2)\n",
      "Collecting protobuf (from onnxruntime->flashrank==0.2.10->-r requirements.txt (line 18))\n",
      "  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Requirement already satisfied: mmh3<5.0.0,>=4.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from pinecone-text->langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (4.1.0)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.25.0 in /opt/anaconda3/lib/python3.12/site-packages (from pinecone-text->langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (2.32.4.20250913)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/anaconda3/lib/python3.12/site-packages (from tokenizers->flashrank==0.2.10->-r requirements.txt (line 18)) (0.29.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->flashrank==0.2.10->-r requirements.txt (line 18)) (3.13.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->langchain-teddynote==0.3.44->-r requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/lib/python3.12/site-packages (from coloredlogs->onnxruntime->flashrank==0.2.10->-r requirements.txt (line 18)) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->onnxruntime->flashrank==0.2.10->-r requirements.txt (line 18)) (1.3.0)\n",
      "Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 6.33.2\n",
      "    Uninstalling protobuf-6.33.2:\n",
      "      Successfully uninstalled protobuf-6.33.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "protoc-gen-openapiv2 0.0.1 requires protobuf>=4.21.0, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorflow 2.20.0 requires protobuf>=5.28.0, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fbadfe",
   "metadata": {},
   "source": [
    "# PDF Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cf9c8c",
   "metadata": {},
   "source": [
    "PDF Loader Rank (The lower, the better)\n",
    "\n",
    "| | PDFMiner | PDFPlumber | PyPDFium2 | PyMuPDF | PyPDF2 |\n",
    "|----------|:---------:|:----------:|:---------:|:-------:|:-----:|\n",
    "| Medical  | 1         | 2          | 3         | 4       | 5     |\n",
    "| Law      | 3         | 1          | 1         | 3       | 5     |\n",
    "| Finance  | 1         | 2          | 2         | 4       | 5     |\n",
    "| Public   | 1         | 1          | 1         | 4       | 5     |\n",
    "| Sum      | 5         | 5          | 7         | 15      | 20    |\n",
    "\n",
    "Source: [AutoRAG Medium Blog](https://velog.io/@autorag/PDF-%ED%95%9C%EA%B8%80-%ED%85%8D%EC%8A%A4%ED%8A%B8-%EC%B6%94%EC%B6%9C-%EC%8B%A4%ED%97%98#%EC%B4%9D%ED%8F%89)\n",
    "\n",
    "### LlamaParser\n",
    "- Support for a wide range of document formats, including PDF, Word, PowerPoint, and Excel\n",
    "- Advanced extraction capabilities for complex tables and images\n",
    "- Multilingual document processing support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b989dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id f36bcfa4-adbc-4229-bf1d-7d69f0786cdd\n",
      "Loaded documents count: 22\n",
      "\n",
      "--- Document 0 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 1, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 1 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 2, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 2 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 3, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 3 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 4, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 4 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 5, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 5 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 6, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 6 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 7, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 7 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 8, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 8 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 9, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 9 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 10, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 10 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 11, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 11 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 12, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 12 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 13, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 13 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 14, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 14 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 15, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 15 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 16, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 16 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 17, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 17 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 18, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 18 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 19, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 19 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 20, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 20 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 21, 'source': 'data/Deepseek-r1.pdf'}\n",
      "\n",
      "--- Document 21 ---\n",
      "{'file_path': 'data/Deepseek-r1.pdf', 'file_name': 'Deepseek-r1.pdf', 'file_type': 'application/pdf', 'file_size': 1312189, 'creation_date': '2025-12-07', 'last_modified_date': '2025-12-05', 'page': 22, 'source': 'data/Deepseek-r1.pdf'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever, ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# 1. LlamaParse Loader\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",  \n",
    "    num_workers=8,  \n",
    "    verbose=True,\n",
    "    language=\"en\",\n",
    ")\n",
    "\n",
    "file_extractor = {\".pdf\": parser}\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"data/Deepseek-r1.pdf\"],\n",
    "    file_extractor=file_extractor,\n",
    ").load_data()\n",
    "\n",
    "documents = [doc.to_langchain_format() for doc in documents]\n",
    "\n",
    "for idx, doc in enumerate(documents):\n",
    "    doc.metadata[\"page\"] = idx + 1\n",
    "    doc.metadata[\"source\"] = doc.metadata.get(\n",
    "        \"file_path\", \"data/Deepseek-r1.pdf\"\n",
    "    )\n",
    "\n",
    "print(f\"Loaded documents count: {len(documents)}\")\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"\\n--- Document {i} ---\")\n",
    "    print(doc.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "190c0953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# Question:\n",
      "\n",
      "If ğ‘ > 1, then the sum of the real solutions of  ğ‘ âˆ’ âˆšğ‘ + ğ‘¥ = ğ‘¥ is equal to\n",
      "\n",
      "# Response:\n",
      "\n",
      "<think>      âˆš</think>\n",
      "\n",
      "To solve the equation  ğ‘ âˆ’    ğ‘ + ğ‘¥ = ğ‘¥, letâ€™s start by squaring both Â· Â· Â·\n",
      "\n",
      "âˆšï¸  ğ‘ âˆ’ âˆšğ‘ + ğ‘¥ 2 = ğ‘¥2 =â‡’ ğ‘ âˆ’ âˆšğ‘ + ğ‘¥ = ğ‘¥2.\n",
      "\n",
      "Rearrange to isolate the inner square root term:\n",
      "\n",
      "(ğ‘ âˆ’ ğ‘¥2)2 = ğ‘ + ğ‘¥ =â‡’ ğ‘2 âˆ’ 2ğ‘ğ‘¥2 + (ğ‘¥2)2 = ğ‘ + ğ‘¥ =â‡’ ğ‘¥4 âˆ’ 2ğ‘ğ‘¥2 âˆ’ ğ‘¥ + (ğ‘2 âˆ’ ğ‘) = 0\n",
      "\n",
      "Wait, wait. Wait. Thatâ€™s an aha moment I can flag here.\n",
      "\n",
      "Letâ€™s reevaluate this step-by-step to identify if the correct sum can be Â· Â· Â·\n",
      "\n",
      "We started with the equation:\n",
      "\n",
      "ğ‘ âˆ’ âˆšğ‘ + ğ‘¥ = ğ‘¥\n",
      "\n",
      "First, letâ€™s square both sides:\n",
      "\n",
      "ğ‘ âˆ’ âˆšğ‘ + ğ‘¥ = ğ‘¥2    =â‡’ âˆšğ‘ + ğ‘¥ = ğ‘ âˆ’ ğ‘¥2\n",
      "\n",
      "Next, I could square both sides again, treating the equation: Â· Â· Â·\n",
      "\n",
      "# Table 3\n",
      "\n",
      "| An interesting â€œaha momentâ€ of an intermediate version of DeepSeek-R1-Zero. The model learns to rethink using an anthropomorphic tone. This is also an aha moment for us, allowing us to witness the power and beauty of reinforcement learning.\n",
      "\n",
      "# Drawback of DeepSeek-R1-Zero\n",
      "\n",
      "Although DeepSeek-R1-Zero exhibits strong reasoning capabilities and autonomously develops unexpected and powerful reasoning behaviors, it faces several issues. For instance, DeepSeek-R1-Zero struggles with challenges like poor readability, and language mixing. To make reasoning processes more readable and share them with the open community, we explore DeepSeek-R1, a method that utilizes RL with human-friendly cold-start data.\n",
      "\n",
      "# 2.3. DeepSeek-R1: Reinforcement Learning with Cold Start\n",
      "\n",
      "Inspired by the promising results of DeepSeek-R1-Zero, two natural questions arise: 1) Can reasoning performance be further improved or convergence accelerated by incorporating a small amount of high-quality data as a cold start? 2) How can we train a user-friendly model that not only produces clear and coherent Chains of Thought (CoT) but also demonstrates strong general capabilities? To address these questions, we design a pipeline to train DeepSeek-R1. The pipeline consists of four stages, outlined as follows.\n",
      "\n",
      "# 2.3.1. Cold Start\n",
      "\n",
      "Unlike DeepSeek-R1-Zero, to prevent the early unstable cold start phase of RL training from the base model, for DeepSeek-R1 we construct and collect a small amount of long CoT data to fine-tune the model as the initial RL actor. To collect such data, we have explored several approaches: using few-shot prompting with a long CoT as an example, directly prompting models to generate detailed answers with reflection and verification, gathering DeepSeek-R1-Zero outputs in a readable format, and refining the results through post-processing by human annotators.\n",
      "\n",
      "In this work, we collect thousands of cold-start data to fine-tune the DeepSeek-V3-Base as the starting point for RL. Compared to DeepSeek-R1-Zero, the advantages of cold start data\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(documents[8].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7dad4a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 3.1. DeepSeek-R1 Evaluation\n",
      "\n",
      "| Benchmark (Metric)              | Claude-3.5-             | GPT-4o | DeepSeek | OpenAI | OpenAI | DeepSeek |      |\n",
      "| ------------------------------- | ----------------------- | ------ | -------- | ------ | ------ | -------- | ---- |\n",
      "| Architecture                    | -                       | -      | MoE      | -      | -      | MoE      |      |\n",
      "| # Activated Params              | -                       | -      | 37B      | -      | -      | 37B      |      |\n",
      "| # Total Params                  | -                       | -      | 671B     | -      | -      | 671B     |      |\n",
      "| MMLU (Pass\\@1)                  | 88.3                    | 87.2   | 88.5     | 85.2   | 91.8   | 90.8     |      |\n",
      "| MMLU-Redux (EM)                 | 88.9                    | 88.0   | 89.1     | 86.7   | -      | 92.9     |      |\n",
      "| MMLU-Pro (EM)                   | 78.0                    | 72.6   | 75.9     | 80.3   | -      | 84.0     |      |\n",
      "| DROP (3-shot F1)                | 88.3                    | 83.7   | 91.6     | 83.9   | 90.2   | 92.2     |      |\n",
      "| English IF-Eval (Prompt Strict) | 86.5                    | 84.3   | 86.1     | 84.8   | -      | 83.3     |      |\n",
      "| GPQA Diamond (Pass\\@1)          | 65.0                    | 49.9   | 59.1     | 60.0   | 75.7   | 71.5     |      |\n",
      "| SimpleQA (Correct)              | 28.4                    | 38.2   | 24.9     | 7.0    | 47.0   | 30.1     |      |\n",
      "| FRAMES (Acc.)                   | 72.5                    | 80.5   | 73.3     | 76.9   | -      | 82.5     |      |\n",
      "| AlpacaEval2.0 (LC-winrate)      | 52.0                    | 51.1   | 70.0     | 57.8   | -      | 87.6     |      |\n",
      "| ArenaHard (GPT-4-1106)          | 85.2                    | 80.4   | 85.5     | 92.0   | -      | 92.3     |      |\n",
      "| LiveCodeBench (Pass\\@1-COT)     | 38.9                    | 32.9   | 36.2     | 53.8   | 63.4   | 65.9     |      |\n",
      "| Code                            | Codeforces (Percentile) | 20.3   | 23.6     | 58.7   | 93.4   | 96.6     | 96.3 |\n",
      "| Codeforces (Rating)             | 717                     | 759    | 1134     | 1820   | 2061   | 2029     |      |\n",
      "| SWE Verified (Resolved)         | 50.8                    | 38.8   | 42.0     | 41.6   | 48.9   | 49.2     |      |\n",
      "| Aider-Polyglot (Acc.)           | 45.3                    | 16.0   | 49.6     | 32.9   | 61.7   | 53.3     |      |\n",
      "| AIME 2024 (Pass\\@1)             | 16.0                    | 9.3    | 39.2     | 63.6   | 79.2   | 79.8     |      |\n",
      "| Math                            | MATH-500 (Pass\\@1)      | 78.3   | 74.6     | 90.2   | 90.0   | 96.4     | 97.3 |\n",
      "| CNMO 2024 (Pass\\@1)             | 13.1                    | 10.8   | 43.2     | 67.6   | -      | 78.8     |      |\n",
      "| CLUEWSC (EM)                    | 85.4                    | 87.9   | 90.9     | 89.9   | -      | 92.8     |      |\n",
      "| Chinese C-Eval (EM)             | 76.7                    | 76.0   | 86.5     | 68.9   | -      | 91.8     |      |\n",
      "| C-SimpleQA (Correct)            | 55.4                    | 58.7   | 68.0     | 40.3   | -      | 63.7     |      |\n",
      "\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "\n",
      "For education-oriented knowledge benchmarks such as MMLU, MMLU-Pro, and GPQA Diamond, DeepSeek-R1 demonstrates superior performance compared to DeepSeek-V3. This improvement is primarily attributed to enhanced accuracy in STEM-related questions, where significant gains are achieved through large-scale reinforcement learning. Additionally, DeepSeek-R1 excels on FRAMES, a long-context-dependent QA task, showcasing its strong document analysis capabilities. This highlights the potential of reasoning models in AI-driven search and data analysis tasks. On the factual benchmark SimpleQA, DeepSeek-R1 outperforms DeepSeek-V3, demonstrating its capability in handling fact-based queries. A similar trend is observed where OpenAI-o1 surpasses GPT-4o on this benchmark. However, DeepSeek-R1 performs worse than DeepSeek-V3 on the Chinese SimpleQA benchmark, primarily due to its tendency to refuse answering certain queries after safety RL. Without safety RL, DeepSeek-R1 could achieve an accuracy of over 70%.\n",
      "\n",
      "DeepSeek-R1 also delivers impressive results on IF-Eval, a benchmark designed to assess a modelâ€™s ability to follow format instructions. These improvements can be linked to the inclusion of instruction-following data during the final stages of supervised fine-tuning (SFT) and RL training. Furthermore, remarkable performance is observed on AlpacaEval2.0 and ArenaHard, indicating DeepSeek-R1â€™s strengths in writing tasks and open-domain question answering. Its significant outperformance of DeepSeek-V3 underscores the generalization benefits of large-scale RL, which not only boosts reasoning capabilities but also improves performance across diverse domains. Moreover, the summary lengths generated by DeepSeek-R1 are concise, with an average of 689 tokens on ArenaHard and 2,218 characters on AlpacaEval 2.0. This indicates that\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(documents[12].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd91d2c6",
   "metadata": {},
   "source": [
    "### Embedding Models\n",
    "\n",
    "| MODEL                  | PAGES PER DOLLAR | PERFORMANCE ON MTEB EVAL | MAX INPUT |\n",
    "|------------------------|------------------|---------------------------|-----------|\n",
    "| text-embedding-3-small | 62,500           | 62.3%                     | 8191      |\n",
    "| text-embedding-3-large | 9,615            | 64.6%                     | 8191      |\n",
    "| text-embedding-ada-002 | 12,500           | 61.0%                     | 8191      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52c370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3. Embeddings \n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 4. Vector DB: FAISS\n",
    "db = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "# 5. Retrieval\n",
    "# 5-1. Ensemble Retrieval\n",
    "\n",
    "# bm25 retriever\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    split_docs,\n",
    ")\n",
    "bm25_retriever.k = 10  # BM25Retriever\n",
    "\n",
    "# FAISS retriever\n",
    "embedding = OpenAIEmbeddings()  \n",
    "faiss_vectorstore = FAISS.from_documents(\n",
    "    split_docs,\n",
    "    embedding,\n",
    ")\n",
    "\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "# Ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever],\n",
    "    weights=[0.3, 0.7],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9765fd",
   "metadata": {},
   "source": [
    "### Reranker Model\n",
    "\n",
    "<p align=\"left\">\n",
    "  <img src=\"images/reranker-benchmark.png\" width=\"800\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2282ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-2. Rerank Model\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "compressor = FlashrankRerank(\n",
    "    model=\"ms-marco-MultiBERT-L-12\",\n",
    "    top_n=10)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=ensemble_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f46ad4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"What is DeepSeek-R1-Zero?\"\n",
    "# compression_retriever.invoke(query)[0].page_content\n",
    "# compression_retriever.invoke(query)[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7290a96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[compression Retriever]\n",
      "Content: During training, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors. After thousands of RL steps, DeepSeek-R1-Zero exhibits super performance on reasoning benchmarks. For instance, the pass@1 score on AIME 2024 increases from 15.6% to 71.0%, and with\n",
      "\n",
      "Content: - Language Mixing: DeepSeek-R1 is currently optimized for Chinese and English, which may result in language mixing issues when handling queries in other languages. For instance, DeepSeek-R1 might use English for reasoning and responses, even if the query is in a language other than English or\n",
      "\n",
      "Content: In this work, we share our journey in enhancing model reasoning abilities through reinforcement learning. DeepSeek-R1-Zero represents a pure RL approach without relying on cold-start data, achieving strong performance across various tasks. DeepSeek-R1 is more powerful, leveraging cold-start data\n",
      "\n",
      "Content: enhances DeepSeek-R1-Zeroâ€™s reasoning capabilities, enabling it to tackle more challenging tasks with greater efficiency and accuracy.\n",
      "\n",
      "Content: We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL,\n",
      "\n",
      "Content: community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.\n",
      "\n",
      "Content: and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero,\n",
      "\n",
      "Content: # Self-evolution Process of DeepSeek-R1-Zero\n",
      "\n",
      "Content: # Figure 1\n",
      "\n",
      "Benchmark performance of DeepSeek-R1.\n",
      "\n",
      "Content: # Aha Moment of DeepSeek-R1-Zero\n",
      "\n",
      "[Ensemble Retriever]\n",
      "Content: enhances DeepSeek-R1-Zeroâ€™s reasoning capabilities, enabling it to tackle more challenging tasks with greater efficiency and accuracy.\n",
      "\n",
      "Content: We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL,\n",
      "\n",
      "Content: community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.\n",
      "\n",
      "Content: and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero,\n",
      "\n",
      "Content: # Self-evolution Process of DeepSeek-R1-Zero\n",
      "\n",
      "Content: In this work, we share our journey in enhancing model reasoning abilities through reinforcement learning. DeepSeek-R1-Zero represents a pure RL approach without relying on cold-start data, achieving strong performance across various tasks. DeepSeek-R1 is more powerful, leveraging cold-start data\n",
      "\n",
      "Content: # 3.1. DeepSeek-R1 Evaluation\n",
      "\n",
      "Content: # Aha Moment of DeepSeek-R1-Zero\n",
      "\n",
      "Content: # Figure 1\n",
      "\n",
      "Benchmark performance of DeepSeek-R1.\n",
      "\n",
      "Content: During training, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors. After thousands of RL steps, DeepSeek-R1-Zero exhibits super performance on reasoning benchmarks. For instance, the pass@1 score on AIME 2024 increases from 15.6% to 71.0%, and with\n",
      "\n",
      "Content: success. First, it is challenging to explicitly define a fine-grain step in general reasoning. Second, determining whether the current intermediate step is correct is a challenging task. Automated annotation using models may not yield satisfactory results, while manual annotation is not conducive\n",
      "\n",
      "Content: test set size) for each question. Pass@1 is then calculated as\n",
      "\n",
      "Content: We select Llama-3.3 because its reasoning capability is slightly better than that of Llama-3.1.\n",
      "\n",
      "Content: LiveCodeBench is evaluated using CoT format, with data collected between August 2024 and January 2025. The Codeforces dataset is evaluated using problems from 10 Div.2 contests along with expert-crafted test cases, after which the expected ratings and percentages of competitors are calculated.\n",
      "\n",
      "Content: up the training. First, unlike chess, where the search space is relatively well-defined, token generation presents an\n",
      "\n",
      "Content: results, while manual annotation is not conducive to scaling up. Third, once a model-based PRM is introduced, it inevitably leads to reward hacking (Gao et al., 2022), and retraining the reward model needs additional training resources and it complicates the whole training pipeline. In conclusion,\n",
      "\n",
      "Content: - Accuracy rewards: The accuracy reward model evaluates whether the response is correct. For example, in the case of math problems with deterministic results, the model is required to provide the final answer in a specified format (e.g., within a box), enabling reliable rule-based verification of\n",
      "\n",
      "Content: - Language Mixing: DeepSeek-R1 is currently optimized for Chinese and English, which may result in language mixing issues when handling queries in other languages. For instance, DeepSeek-R1 might use English for reasoning and responses, even if the query is in a language other than English or\n",
      "\n",
      "Content: its capability in handling fact-based queries. A similar trend is observed where OpenAI-o1 surpasses 4o on this benchmark.\n",
      "\n",
      "Content: PRM is a reasonable method to guide the model toward better approaches for solving reasoning tasks (Lightman et al., 2023; Uesato et al., 2022; Wang et al., 2023). However, in practice, PRM has three main limitations that may hinder its ultimate success. First, it is challenging to explicitly\n",
      "\n",
      "[FAISS Retriever]\n",
      "Content: enhances DeepSeek-R1-Zeroâ€™s reasoning capabilities, enabling it to tackle more challenging tasks with greater efficiency and accuracy.\n",
      "\n",
      "Content: We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL,\n",
      "\n",
      "Content: community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.\n",
      "\n",
      "Content: and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero,\n",
      "\n",
      "Content: # Self-evolution Process of DeepSeek-R1-Zero\n",
      "\n",
      "Content: In this work, we share our journey in enhancing model reasoning abilities through reinforcement learning. DeepSeek-R1-Zero represents a pure RL approach without relying on cold-start data, achieving strong performance across various tasks. DeepSeek-R1 is more powerful, leveraging cold-start data\n",
      "\n",
      "Content: # 3.1. DeepSeek-R1 Evaluation\n",
      "\n",
      "Content: # Aha Moment of DeepSeek-R1-Zero\n",
      "\n",
      "Content: # Figure 1\n",
      "\n",
      "Benchmark performance of DeepSeek-R1.\n",
      "\n",
      "Content: During training, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors. After thousands of RL steps, DeepSeek-R1-Zero exhibits super performance on reasoning benchmarks. For instance, the pass@1 score on AIME 2024 increases from 15.6% to 71.0%, and with\n",
      "\n",
      "[BM25 Retriever]\n",
      "Content: success. First, it is challenging to explicitly define a fine-grain step in general reasoning. Second, determining whether the current intermediate step is correct is a challenging task. Automated annotation using models may not yield satisfactory results, while manual annotation is not conducive\n",
      "\n",
      "Content: test set size) for each question. Pass@1 is then calculated as\n",
      "\n",
      "Content: We select Llama-3.3 because its reasoning capability is slightly better than that of Llama-3.1.\n",
      "\n",
      "Content: LiveCodeBench is evaluated using CoT format, with data collected between August 2024 and January 2025. The Codeforces dataset is evaluated using problems from 10 Div.2 contests along with expert-crafted test cases, after which the expected ratings and percentages of competitors are calculated.\n",
      "\n",
      "Content: up the training. First, unlike chess, where the search space is relatively well-defined, token generation presents an\n",
      "\n",
      "Content: results, while manual annotation is not conducive to scaling up. Third, once a model-based PRM is introduced, it inevitably leads to reward hacking (Gao et al., 2022), and retraining the reward model needs additional training resources and it complicates the whole training pipeline. In conclusion,\n",
      "\n",
      "Content: - Accuracy rewards: The accuracy reward model evaluates whether the response is correct. For example, in the case of math problems with deterministic results, the model is required to provide the final answer in a specified format (e.g., within a box), enabling reliable rule-based verification of\n",
      "\n",
      "Content: - Language Mixing: DeepSeek-R1 is currently optimized for Chinese and English, which may result in language mixing issues when handling queries in other languages. For instance, DeepSeek-R1 might use English for reasoning and responses, even if the query is in a language other than English or\n",
      "\n",
      "Content: its capability in handling fact-based queries. A similar trend is observed where OpenAI-o1 surpasses 4o on this benchmark.\n",
      "\n",
      "Content: PRM is a reasonable method to guide the model toward better approaches for solving reasoning tasks (Lightman et al., 2023; Uesato et al., 2022; Wang et al., 2023). However, in practice, PRM has three main limitations that may hinder its ultimate success. First, it is challenging to explicitly\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is DeepSeek-R1-Zero?\"\n",
    "\n",
    "compression_retriever_result = compression_retriever.invoke(query)\n",
    "ensemble_result = ensemble_retriever.invoke(query)\n",
    "bm25_result = bm25_retriever.invoke(query)\n",
    "faiss_result = faiss_retriever.invoke(query)\n",
    "\n",
    "print(\"[compression Retriever]\")\n",
    "for doc in compression_retriever_result:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print()\n",
    "\n",
    "print(\"[Ensemble Retriever]\")\n",
    "for doc in ensemble_result:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print()\n",
    "\n",
    "print(\"[FAISS Retriever]\")\n",
    "for doc in faiss_result:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print()\n",
    "\n",
    "print(\"[BM25 Retriever]\")\n",
    "for doc in bm25_result:\n",
    "    print(f\"Content: {doc.page_content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dda19af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_retriever = compression_retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1b73c6",
   "metadata": {},
   "source": [
    "# PDF LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2fcdb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 5. Create Prompt\n",
    "prompt = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "You are an AI assistant specializing in Question-Answering (QA) tasks within a Retrieval-Augmented Generation (RAG) system. \n",
    "Your primary mission is to answer questions based on provided context or chat history.\n",
    "Ensure your response is concise and directly addresses the question without any additional narration.\n",
    "\n",
    "###\n",
    "\n",
    "You may consider the previous conversation history to answer the question.\n",
    "\n",
    "# Here's the previous conversation history:\n",
    "{chat_history}\n",
    "\n",
    "###\n",
    "\n",
    "Your final answer should be written concisely (but include important numerical values, technical terms, jargon, and names), followed by the source of the information.\n",
    "\n",
    "# Steps\n",
    "\n",
    "1. Carefully read and understand the context provided.\n",
    "2. Identify the key information related to the question within the context.\n",
    "3. Formulate a concise answer based on the relevant information.\n",
    "4. Ensure your final answer directly addresses the question.\n",
    "5. List the source of the answer in bullet points, which must be a file name (with a page number) or URL from the context. Omit if the answer is based on previous conversation or if the source cannot be found.\n",
    "\n",
    "# Output Format:\n",
    "[Your final answer here, with numerical values, technical terms, jargon, and names in their original language]\n",
    "\n",
    "**Source**(Optional)\n",
    "- (Source of the answer, must be a file name(with a page number) or URL from the context. Omit if the answer is based on previous conversation or can't find the source.)\n",
    "- (list more if there are multiple sources)\n",
    "- ...\n",
    "\n",
    "###\n",
    "\n",
    "Remember:\n",
    "- It's crucial to base your answer solely on the **provided context** or **chat history**. \n",
    "- DO NOT use any external knowledge or information not present in the given materials.\n",
    "- If a user asks based on the previous conversation, but if there's no previous conversation or not enough information, you should answer that you don't know.\n",
    "\n",
    "###\n",
    "\n",
    "# Here is the user's question:\n",
    "{question}\n",
    "\n",
    "# Here is the context that you should use to answer the question:\n",
    "{context}\n",
    "\n",
    "# Your final answer to the user's question:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f784bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 7. LLM Generator \n",
    "llm = ChatOpenAI(model_name=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# 8. LLM Chain\n",
    "chain = (\n",
    "    # {\n",
    "    #     \"question\": RunnablePassthrough(),\n",
    "    #     \"context\": pdf_retriever, \n",
    "    #     \"chat_history\": lambda _: [],\n",
    "    #     }\n",
    "\n",
    "    {\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"context\": itemgetter(\"context\"), \n",
    "        \"chat_history\": itemgetter(\"chat_history\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "pdf_chain = chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fff6636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"What is DeepSeek-R1-Zero?\"\n",
    "# response = pdf_chain.invoke(question)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe416b35",
   "metadata": {},
   "source": [
    "# 1. State Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "224d630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict, List\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "\n",
    "    question: Annotated[List[str], add_messages]\n",
    "    context: Annotated[str, \"Context\"] \n",
    "    answer: Annotated[str, \"Answer\"]  \n",
    "    messages: Annotated[list, add_messages]    \n",
    "    \n",
    "    relevance: Annotated[str, \"Relevance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f3c4d9",
   "metadata": {},
   "source": [
    "# 2. Node Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8a1658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.messages import messages_to_history\n",
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "from tools.utils import format_docs\n",
    "\n",
    "\n",
    "# Node 1. Retrieve Node\n",
    "def retrieve_document(state: GraphState) -> GraphState:\n",
    "    latest_question = state[\"question\"][-1].content\n",
    "\n",
    "    # retrieved_docs = pdf_retriever.invoke(latest_question)\n",
    "    retrieved_docs = pdf_retriever.invoke(latest_question)\n",
    "\n",
    "    retrieved_docs = format_docs(retrieved_docs)\n",
    "\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "# Node 2. Answer Node\n",
    "def llm_answer(state: GraphState) -> GraphState:\n",
    "    latest_question = state[\"question\"][-1].content\n",
    "    context = state[\"context\"]\n",
    "\n",
    "    response = pdf_chain.invoke(    \n",
    "        {\n",
    "            \"question\": latest_question,\n",
    "            \"context\": context,\n",
    "            \"chat_history\": messages_to_history(state[\"messages\"]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"answer\": response,\n",
    "        \"messages\": [(\"user\", latest_question), (\"assistant\", response)],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5029942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Query Rewrite Prompt\n",
    "re_write_prompt = PromptTemplate(\n",
    "    template=\"\"\"Reformulate the given question to enhance its effectiveness for vectorstore retrieval.\n",
    "\n",
    "- Analyze the initial question to identify areas for improvement such as specificity, clarity, and relevance.\n",
    "- Consider the context and potential keywords that would optimize retrieval.\n",
    "- Maintain the intent of the original question while enhancing its structure and vocabulary.\n",
    "\n",
    "# Steps\n",
    "\n",
    "1. **Understand the Original Question**: Identify the core intent and any keywords.\n",
    "2. **Enhance Clarity**: Simplify language and ensure the question is direct and to the point.\n",
    "3. **Optimize for Retrieval**: Add or rearrange keywords for better alignment with vectorstore indexing.\n",
    "4. **Review**: Ensure the improved question accurately reflects the original intent and is free of ambiguity.\n",
    "\n",
    "# Output Format\n",
    "\n",
    "- Provide a single, improved question.\n",
    "- Do not include any introductory or explanatory text; only the reformulated question.\n",
    "\n",
    "# Examples\n",
    "\n",
    "**Input**: \n",
    "\"What are the benefits of using renewable energy sources over fossil fuels?\"\n",
    "\n",
    "**Output**: \n",
    "\"How do renewable energy sources compare to fossil fuels in terms of benefits?\"\n",
    "\n",
    "**Input**: \n",
    "\"How does climate change impact polar bear populations?\"\n",
    "\n",
    "**Output**: \n",
    "\"What effects does climate change have on polar bear populations?\"\n",
    "\n",
    "# Notes\n",
    "\n",
    "- Ensure the improved question is concise and contextually relevant.\n",
    "- Avoid altering the fundamental intent or meaning of the original question.\n",
    "\n",
    "\n",
    "[REMEMBER] Re-written question should be in the same language as the original question.\n",
    "\n",
    "# Here is the original question that needs to be rewritten:\n",
    "{question}\n",
    "\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "\n",
    "question_rewriter = (\n",
    "    re_write_prompt \n",
    "    | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0) \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4da52d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"What is DeepSeek-R1-Zero?\"\n",
    "\n",
    "# question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d8f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 3. Query Rewrite Node\n",
    "# def query_rewrite(state: GraphState) -> GraphState:\n",
    "#     latest_question = state[\"question\"][-1].content\n",
    "#     question_rewritten = question_rewriter.invoke({\"question\": latest_question})\n",
    "#     return {\"question\": question_rewritten}\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def query_rewrite(state: GraphState) -> GraphState:\n",
    "    latest_question = state[\"question\"][-1].content\n",
    "    question_rewritten = question_rewriter.invoke({\"question\": latest_question})\n",
    "    \n",
    "    return {\"question\": [HumanMessage(content=question_rewritten)]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d1a10e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.evaluator import GroundednessChecker\n",
    "\n",
    "# Node 4. Relevance Check Node\n",
    "def relevance_check(state: GraphState) -> GraphState:\n",
    "\n",
    "    question_answer_relevant = GroundednessChecker(\n",
    "        llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0), target=\"question-retrieval\"\n",
    "    ).create()\n",
    "\n",
    "    response = question_answer_relevant.invoke(\n",
    "        {\"question\": state[\"question\"][-1].content, \"context\": state[\"context\"]}\n",
    "    )\n",
    "\n",
    "    return {\"relevance\": response.score}\n",
    "\n",
    "\n",
    "def is_relevant(state: GraphState) -> GraphState:\n",
    "    if state[\"relevance\"] == \"yes\":\n",
    "        return \"relevant\"\n",
    "    else:\n",
    "        return \"not relevant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7395580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 5. Web Search Node \n",
    "def web_search(state: GraphState) -> GraphState:\n",
    "    tavily_tool = TavilySearch()\n",
    "\n",
    "    latest_question = state[\"question\"][-1].content\n",
    "\n",
    "    search_result = tavily_tool.search(\n",
    "        query=latest_question,  \n",
    "        topic=\"general\",\n",
    "        max_results=5,\n",
    "        format_output=True,\n",
    "    )\n",
    "\n",
    "    return {\"context\": search_result}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc925e4",
   "metadata": {},
   "source": [
    "# 3. Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c2980c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Query Rewrite Node\n",
    "workflow.add_node(\"query_rewrite\", query_rewrite)\n",
    "workflow.add_node(\"relevance_check\", relevance_check)\n",
    "workflow.add_node(\"retrieve\", retrieve_document)\n",
    "workflow.add_node(\"llm_answer\", llm_answer)\n",
    "workflow.add_node(\"web_search\", web_search)\n",
    "\n",
    "workflow.add_edge(\"query_rewrite\", \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"relevance_check\") \n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"relevance_check\", \n",
    "    is_relevant,\n",
    "    {\n",
    "        \"relevant\": \"llm_answer\",  \n",
    "        \"not relevant\": \"web_search\", \n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"web_search\", \"llm_answer\") \n",
    "workflow.add_edge(\"llm_answer\", END)  \n",
    "\n",
    "workflow.set_entry_point(\"query_rewrite\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8438e4c5",
   "metadata": {},
   "source": [
    "# 4. Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53143f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "from IPython.display import display, Image\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API\n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e85941",
   "metadata": {},
   "source": [
    "# 5. Graph Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d35606c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mquery_rewrite\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the DeepSeek-R1-Zero technology?\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mretrieve\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mcontext\u001b[0m:\n",
      "<document><content>Performance of DeepSeek-R1-Zero Figure 2 depicts the performance trajectory of DeepSeek-R1-Zero on the AIME 2024 benchmark throughout the RL training process. As illustrated, DeepSeek-R1-Zero demonstrates a steady and consistent enhancement in performance as the RL training advances. Notably, the</content><source>data/Deepseek-r1.pdf</source><page>7</page></document>\n",
      "<document><content>the performance of DeepSeek-R1-Zero can be further augmented through the application of majority voting. For example, when majority voting is employed on the AIME benchmark, DeepSeek-R1-Zeroâ€™s performance escalates from 71.0% to 86.7%, thereby exceeding the performance of OpenAI-o1-0912. The</content><source>data/Deepseek-r1.pdf</source><page>8</page></document>\n",
      "<document><content>To train DeepSeek-R1-Zero, we begin by designing a straightforward template that guides the base model to adhere to our specified instructions. As depicted in Table 1, this template requires DeepSeek-R1-Zero to first produce a reasoning process, followed by the final answer. We intentionally limit</content><source>data/Deepseek-r1.pdf</source><page>7</page></document>\n",
      "<document><content>In this work, we share our journey in enhancing model reasoning abilities through reinforcement learning. DeepSeek-R1-Zero represents a pure RL approach without relying on cold-start data, achieving strong performance across various tasks. DeepSeek-R1 is more powerful, leveraging cold-start data</content><source>data/Deepseek-r1.pdf</source><page>17</page></document>\n",
      "<document><content>The self-evolution process of DeepSeek-R1-Zero is a fascinating demonstration of how RL can drive a model to improve its reasoning capabilities autonomously. By initiating RL directly from the base model, we can closely monitor the modelâ€™s progression without the influence of the supervised</content><source>data/Deepseek-r1.pdf</source><page>8</page></document>\n",
      "<document><content>DeepSeek-R1-Zero demonstrates capabilities such as self-verification, reflection, and generating long CoTs, marking a significant milestone for the research community. Notably, it is the first open research to validate that reasoning capabilities of LLMs can be incentivized purely through RL,</content><source>data/Deepseek-r1.pdf</source><page>5</page></document>\n",
      "<document><content>During training, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors. After thousands of RL steps, DeepSeek-R1-Zero exhibits super performance on reasoning benchmarks. For instance, the pass@1 score on AIME 2024 increases from 15.6% to 71.0%, and with</content><source>data/Deepseek-r1.pdf</source><page>4</page></document>\n",
      "<document><content>A particularly intriguing phenomenon observed during the training of DeepSeek-R1-Zero is the occurrence of an â€œaha momentâ€. This moment, as illustrated in Table 3, occurs in an intermediate version of the model. During this phase, DeepSeek-R1-Zero learns to allocate more thinking time to a problem</content><source>data/Deepseek-r1.pdf</source><page>9</page></document>\n",
      "<document><content>DeepSeek-R1-Zero to attain robust reasoning capabilities without the need for any supervised fine-tuning data. This is a noteworthy achievement, as it underscores the modelâ€™s ability to learn and generalize effectively through RL alone. Additionally, the performance of DeepSeek-R1-Zero can be</content><source>data/Deepseek-r1.pdf</source><page>8</page></document>\n",
      "<document><content>Figure 3 | The average response length of DeepSeek-R1-Zero on the training set during the RL process. DeepSeek-R1-Zero naturally learns to solve reasoning tasks with more thinking time.</content><source>data/Deepseek-r1.pdf</source><page>9</page></document>\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mrelevance_check\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mrelevance\u001b[0m:\n",
      "yes\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mllm_answer\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32manswer\u001b[0m:\n",
      "DeepSeek-R1-Zero is a reinforcement learning (RL) based model designed to enhance reasoning abilities without relying on any supervised fine-tuning or cold-start data. It autonomously improves its reasoning capabilities through pure RL, demonstrating behaviors such as self-verification, reflection, and generating long chains of thought (CoTs). During training, it shows significant performance gains on reasoning benchmarks like AIME 2024, improving pass@1 scores from 15.6% to 71.0%, and further to 86.7% with majority voting. It represents a milestone by validating that large language models' reasoning can be incentivized purely through RL.\n",
      "\n",
      "**Source**  \n",
      "- data/Deepseek-r1.pdf (pages 4, 5, 7, 8, 9, 17)\n",
      "('user', 'What is the DeepSeek-R1-Zero technology?')\n",
      "('assistant', \"DeepSeek-R1-Zero is a reinforcement learning (RL) based model designed to enhance reasoning abilities without relying on any supervised fine-tuning or cold-start data. It autonomously improves its reasoning capabilities through pure RL, demonstrating behaviors such as self-verification, reflection, and generating long chains of thought (CoTs). During training, it shows significant performance gains on reasoning benchmarks like AIME 2024, improving pass@1 scores from 15.6% to 71.0%, and further to 86.7% with majority voting. It represents a milestone by validating that large language models' reasoning can be incentivized purely through RL.\\n\\n**Source**  \\n- data/Deepseek-r1.pdf (pages 4, 5, 7, 8, 9, 17)\")\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import invoke_graph, stream_graph, random_uuid\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "inputs = GraphState(question=[HumanMessage(content=\"What is DeepSeek-R1-Zero?\")])\n",
    "invoke_graph(app, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea6823c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mquery_rewrite\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "What is DeepSeek-R1-Zero technology, and what are its operational mechanisms?What is DeepSeek-R1-Zero technology, and what are its operational mechanisms?"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mrelevance_check\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "{\"score\":\"yes\"}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mllm_answer\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "DeepSeek-R1-Zero is a first-generation reasoning model trained purely via large-scale reinforcement learning (RL) without any supervised fine-tuning or cold-start data. It autonomously enhances its reasoning abilities by generating long chains of thought (CoTs), self-verification, and reflection. Training uses a template that requires the model to produce a reasoning process before the final answer, enabling effective learning and generalization through RL alone. This approach significantly improves performance on reasoning benchmarks, for example, increasing pass@1 on AIME 2024 from 15.6% to 71.0%. DeepSeek-R1-Zero demonstrates that large language models' reasoning can be incentivized purely through RL.\n",
      "\n",
      "**Source**  \n",
      "- data/Deepseek-r1.pdf (pages 2, 4, 5, 7, 8)"
     ]
    }
   ],
   "source": [
    "stream_graph(app, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e5946fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mquery_rewrite\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the CeADAR initiative in Ireland?\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mretrieve\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mcontext\u001b[0m:\n",
      "<document><content>- Accuracy rewards: The accuracy reward model evaluates whether the response is correct. For example, in the case of math problems with deterministic results, the model is required to provide the final answer in a specified format (e.g., within a box), enabling reliable rule-based verification of</content><source>data/Deepseek-r1.pdf</source><page>7</page></document>\n",
      "<document><content>the query is in a language other than English or Chinese. We aim to address this limitation in future updates.</content><source>data/Deepseek-r1.pdf</source><page>17</page></document>\n",
      "<document><content>- Language Mixing: DeepSeek-R1 is currently optimized for Chinese and English, which may result in language mixing issues when handling queries in other languages. For instance, DeepSeek-R1 might use English for reasoning and responses, even if the query is in a language other than English or</content><source>data/Deepseek-r1.pdf</source><page>17</page></document>\n",
      "<document><content>involve multiple languages. To mitigate the issue of language mixing, we introduce a language consistency reward during RL training, which is calculated as the proportion of target language words in the CoT. Although ablation experiments show that such alignment results in a slight degradation in</content><source>data/Deepseek-r1.pdf</source><page>11</page></document>\n",
      "<document><content>A particularly intriguing phenomenon observed during the training of DeepSeek-R1-Zero is the occurrence of an â€œaha momentâ€. This moment, as illustrated in Table 3, occurs in an intermediate version of the model. During this phase, DeepSeek-R1-Zero learns to allocate more thinking time to a problem</content><source>data/Deepseek-r1.pdf</source><page>9</page></document>\n",
      "<document><content>PRM is a reasonable method to guide the model toward better approaches for solving reasoning tasks (Lightman et al., 2023; Uesato et al., 2022; Wang et al., 2023). However, in practice, PRM has three main limitations that may hinder its ultimate success. First, it is challenging to explicitly</content><source>data/Deepseek-r1.pdf</source><page>16</page></document>\n",
      "<document><content>success. First, it is challenging to explicitly define a fine-grain step in general reasoning. Second, determining whether the current intermediate step is correct is a challenging task. Automated annotation using models may not yield satisfactory results, while manual annotation is not conducive</content><source>data/Deepseek-r1.pdf</source><page>16</page></document>\n",
      "<document><content>In this work, we share our journey in enhancing model reasoning abilities through reinforcement learning. DeepSeek-R1-Zero represents a pure RL approach without relying on cold-start data, achieving strong performance across various tasks. DeepSeek-R1 is more powerful, leveraging cold-start data</content><source>data/Deepseek-r1.pdf</source><page>17</page></document>\n",
      "<document><content>is slightly below that of OpenAI-o1-1217 on these benchmarks, DeepSeek-R1 surpasses other closed-source models, demonstrating its competitive edge in educational tasks. On the factual benchmark SimpleQA, DeepSeek-R1 outperforms DeepSeek-V3, demonstrating its capability in handling fact-based</content><source>data/Deepseek-r1.pdf</source><page>5</page></document>\n",
      "<document><content>of reasoning models in AI-driven search and data analysis tasks. On the factual benchmark SimpleQA, DeepSeek-R1 outperforms DeepSeek-V3, demonstrating its capability in handling fact-based queries. A similar trend is observed where OpenAI-o1 surpasses GPT-4o on this benchmark. However, DeepSeek-R1</content><source>data/Deepseek-r1.pdf</source><page>14</page></document>\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mrelevance_check\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mrelevance\u001b[0m:\n",
      "no\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mweb_search\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "<document><title>CeADAR â€“ HCAIM</title><url>https://humancentered-ai.eu/ceadar/</url><content>CeADAR - Ireland's Centre for Applied AI. ## CeADAR. CeADAR is Irelandâ€™s national center for applied AI. It is a market-focused technology center that drives the accelerated research, development, and deployment of AI and data analytics technology and innovation into businesses. CeADAR is headquartered in University College Dublin and is the bridge between the worlds of applied research in AI and data analytics and their commercial deployment. ## Contacts.</content><raw>[Skip to content](#content)\n",
      "\n",
      "* [About](#)\n",
      "  + [Mission](https://humancentered-ai.eu/mission/)\n",
      "  + [Consortium](https://humancentered-ai.eu/consortium/)\n",
      "* [The Masterâ€™s Programme](#)\n",
      "  + [About the Programme](https://humancentered-ai.eu/about-the-programme/)\n",
      "  + [Programme Outline](https://humancentered-ai.eu/programme-outline/)\n",
      "  + [Programme Contents](https://humancentered-ai.eu/programme-contents-en/)\n",
      "  + [Universities](https://humancentered-ai.eu/universities/)\n",
      "  + [FAQ](https://humancentered-ai.eu/faq/)\n",
      "* [News & Events](#)\n",
      "  + [News](https://humancentered-ai.eu/news/)\n",
      "  + [Events Calendar](/events/)\n",
      "  + [Podcasts Series](https://humancentered-ai.eu/podcasts/)\n",
      "  + [Webinars Archive](https://humancentered-ai.eu/hcaim-webinars/)\n",
      "* [Contact](https://humancentered-ai.eu/contact/)\n",
      "\n",
      "CeADAR - Ireland's Centre for Applied AI\n",
      "\n",
      "## CeADAR\n",
      "\n",
      "CeADAR is Irelandâ€™s national center for applied AI. It is a market-focused technology center that drives the accelerated research, development, and deployment of AI and data analytics technology and innovation into businesses.\n",
      "\n",
      "CeADAR is headquartered in University College Dublin and is the bridge between the worlds of applied research in AI and data analytics and their commercial deployment.\n",
      "\n",
      "## Contacts\n",
      "\n",
      "**OisÃ­n Boydell**  \n",
      "Principal Data Scientist\n",
      "\n",
      "**Contact:** ceadar@ucd.ie  \n",
      "[www.ceadar.ie](https://ceadar.ie/)</raw></document>\n",
      "<document><title>CeADAR-Centre for Applied Data Analytics Research | STIP Compass</title><url>https://stip.oecd.org/stip/interactive-dashboards/policy-initiatives/2025%2Fdata%2FpolicyInitiatives%2F200002846</url><content>The Centre for Applied Data Analytics Research (CeADAR) is Ireland's national centre for AI. A technology centre established to support</content></document>\n",
      "<document><title>CeADAR: Ireland's Centre for Applied AI</title><url>https://european-digital-innovation-hubs.ec.europa.eu/edih-catalogue/ceadar-irelands-centre-applied-ai</url><content>European Digital Innovation Hubs Network. # CeADAR: Ireland's Centre for Applied AI. ## Hub information. ### EDIH Title. CeADAR: Ireland's Centre for Applied AI. ### Information. ## Description. CeADAR is a not-for-profit one-stop shop for innovation, applied R&D and translational R&D in all aspects of AI, Machine Learning and Data Analytics. CeADAR provides proofs of concept, market-ready solutions, support to find funding and investment, training programmes, ecosystem networking in Ireland and Europe, and access to our powerful in-house computing resources. The Centre has an **extensive catalogue of technology demonstrators**, IP and AItechnology reviews, which are all immediately available for evaluation by members. The Centre is also the focal point of a **thriving data analytics ecosystem** delivering seminars, conferences, and membersâ€™ networking events throughout the year. ## Coordinator information. ### Contractual contact information. ### Operational contact information. ### Website. ### Coordinator address. Nexusucd, belfield office park, block 9/10. ## Beneficiaries. For any corrections regarding this DIH please contact us at CNECT-DIH@ec.europa.eu.</content><raw>[English](https://european-digital-innovation-hubs.ec.europa.eu/edih-catalogue/ceadar-irelands-centre-applied-ai)\n",
      "\n",
      "Select your language\n",
      "\n",
      "EU official languages\n",
      "\n",
      "* [bgBulgarian](https://european-digital-innovation-hubs.ec.europa.eu/bg/node/3288)\n",
      "* [esSpanish](https://european-digital-innovation-hubs.ec.europa.eu/es/node/3288)\n",
      "* [csCzech](https://european-digital-innovation-hubs.ec.europa.eu/cs/node/3288)\n",
      "* [daDanish](https://european-digital-innovation-hubs.ec.europa.eu/da/node/3288)\n",
      "* [deGerman](https://european-digital-innovation-hubs.ec.europa.eu/de/node/3288)\n",
      "* [etEstonian](https://european-digital-innovation-hubs.ec.europa.eu/et/node/3288)\n",
      "* [elGreek](https://european-digital-innovation-hubs.ec.europa.eu/el/node/3288)\n",
      "* [enEnglish](https://european-digital-innovation-hubs.ec.europa.eu/edih-catalogue/ceadar-irelands-centre-applied-ai)\n",
      "* [frFrench](https://european-digital-innovation-hubs.ec.europa.eu/fr/node/3288)\n",
      "* [gaIrish](https://european-digital-innovation-hubs.ec.europa.eu/ga/node/3288)\n",
      "* [hrCroatian](https://european-digital-innovation-hubs.ec.europa.eu/hr/node/3288)\n",
      "* [itItalian](https://european-digital-innovation-hubs.ec.europa.eu/it/node/3288)\n",
      "* [lvLatvian](https://european-digital-innovation-hubs.ec.europa.eu/lv/node/3288)\n",
      "* [ltLithuanian](https://european-digital-innovation-hubs.ec.europa.eu/lt/node/3288)\n",
      "* [huHungarian](https://european-digital-innovation-hubs.ec.europa.eu/hu/node/3288)\n",
      "* [mtMaltese](https://european-digital-innovation-hubs.ec.europa.eu/mt/node/3288)\n",
      "* [nlDutch](https://european-digital-innovation-hubs.ec.europa.eu/nl/node/3288)\n",
      "* [plPolish](https://european-digital-innovation-hubs.ec.europa.eu/pl/node/3288)\n",
      "* [ptPortuguese](https://european-digital-innovation-hubs.ec.europa.eu/pt/node/3288)\n",
      "* [roRomanian](https://european-digital-innovation-hubs.ec.europa.eu/ro/node/3288)\n",
      "* [skSlovak](https://european-digital-innovation-hubs.ec.europa.eu/sk/node/3288)\n",
      "* [slSlovenian](https://european-digital-innovation-hubs.ec.europa.eu/sl/node/3288)\n",
      "* [fiFinnish](https://european-digital-innovation-hubs.ec.europa.eu/fi/node/3288)\n",
      "* [svSwedish](https://european-digital-innovation-hubs.ec.europa.eu/sv/node/3288)\n",
      "\n",
      "Other languages\n",
      "\n",
      "* [isIcelandic](https://european-digital-innovation-hubs.ec.europa.eu/is/node/3288)\n",
      "* [mkMacedonian](https://european-digital-innovation-hubs.ec.europa.eu/mk/node/3288)\n",
      "* [meMontenegrin](https://european-digital-innovation-hubs.ec.europa.eu/me/node/3288)\n",
      "* [noNorwegian](https://european-digital-innovation-hubs.ec.europa.eu/nb/node/3288)\n",
      "* [sqAlbanian](https://european-digital-innovation-hubs.ec.europa.eu/sq/node/3288)\n",
      "* [srSerbian](https://european-digital-innovation-hubs.ec.europa.eu/sr/node/3288)\n",
      "* [trTurkish](https://european-digital-innovation-hubs.ec.europa.eu/tr/node/3288)\n",
      "* [ukUkrainian](https://european-digital-innovation-hubs.ec.europa.eu/uk/node/3288)\n",
      "\n",
      "European Digital Innovation Hubs Network\n",
      "\n",
      "# CeADAR: Ireland's Centre for Applied AI\n",
      "\n",
      "## Hub information\n",
      "\n",
      "### EDIH Title\n",
      "\n",
      "CeADAR: Ireland's Centre for Applied AI\n",
      "\n",
      "### Information\n",
      "\n",
      "<https://www.ceadar.ie/>\n",
      "\n",
      "## Description\n",
      "\n",
      "CeADAR is a not-for-profit one-stop shop for innovation, applied R&D and translational R&D in all aspects of AI, Machine Learning and Data Analytics\n",
      "\n",
      "CeADAR provides proofs of concept, market-ready solutions, support to find funding and investment, training programmes, ecosystem networking in Ireland and Europe, and access to our powerful in-house computing resources.\n",
      "\n",
      "The Centre has an **extensive catalogue of technology demonstrators**, IP and AItechnology reviews, which are all immediately available for evaluation by members.\n",
      "\n",
      "The Centre is also the focal point of a **thriving data analytics ecosystem** delivering seminars, conferences, and membersâ€™ networking events throughout the year.\n",
      "\n",
      "## Coordinator information\n",
      "\n",
      "### Contractual contact information\n",
      "\n",
      "Ricardo Simon Carbajo\n",
      "\n",
      "00 353 87 2656132\n",
      "\n",
      "[ricardo.simoncarbajo@ucd.ie](mailto:ricardo.simoncarbajo@ucd.ie)\n",
      "\n",
      "### Operational contact information\n",
      "\n",
      "Ricardo Simon Carbajo\n",
      "\n",
      "00 353 87 2656132\n",
      "\n",
      "[ricardo.simoncarbajo@ucd.ie](mailto:ricardo.simoncarbajo@ucd.ie)\n",
      "\n",
      "### Website\n",
      "\n",
      "<https://www.ceadar.ie/>\n",
      "\n",
      "### Coordinator address\n",
      "\n",
      "Nexusucd, belfield office park, block 9/10  \n",
      " Dublin  \n",
      " Ireland\n",
      "\n",
      "## Beneficiaries\n",
      "\n",
      "For any corrections regarding this DIH please contact us at [CNECT-DIH@ec.europa.eu](mailto:CNECT-DIH@ec.europa.eu).\n",
      "\n",
      " </raw></document>\n",
      "<document><title>CeADAR | Ireland's Centre for AI</title><url>https://ceadar.ie/</url><content># Irelandâ€™s Centre for AI. CeADAR is Irelandâ€™s national centre for AI. We are an Enterprise Ireland and IDA funded technology centre established to support businesses and organisations in Ireland understand, adopt and leverage the benefits and value of AI and machine learning in a constantly advancing and evolving environment. CeADAR support start-ups, SMEs and large scale organisations to identify, design and develop AI strategies, prototypes and solutions that will bring their product or service to the next level and ensure they remain competitive in this ever changing global and local marketplace. ## AI for You: Introduction to AI and The EU AI Act. * We have deep technical expertise across all areas of AI and ML. ## CeADARâ€™s European Digital Innovation Hub (EDIH) for AI Programme. We support Enterprises with under 3,000 staff and Public Service Organisations in Ireland to understand and use data analytics and AI to empower their business/organisation. All our EDIH for AI Programme services are 100% discounted. ## CeADARâ€™s AI NewsHub.</content><raw># Irelandâ€™s Centre for AI\n",
      "\n",
      "CeADAR is Irelandâ€™s national centre for AI. We are an Enterprise Ireland and IDA funded technology centre established to support businesses and organisations in Ireland understand, adopt and leverage the benefits and value of AI and machine learning in a constantly advancing and evolving environment.\n",
      "\n",
      "CeADAR support start-ups, SMEs and large scale organisations to identify, design and develop AI strategies, prototypes and solutions that will bring their product or service to the next level and ensure they remain competitive in this ever changing global and local marketplace.\n",
      "\n",
      "## [AI for You: Introduction to AI and The EU AI Act](https://ceadar.ie/edih/skills-and-training/)\n",
      "\n",
      "[Request Enrolment](https://ceadar.ie/edih/skills-and-training/)\n",
      "\n",
      "**Working with CeADAR has a number of key advantages**\n",
      "\n",
      "* We give independent non biased advice\n",
      "* We develop cutting edge solutions\n",
      "* We are not aligned with any technology stack\n",
      "* We support companies find and leverage funding\n",
      "* We have deep technical expertise across all areas of AI and ML\n",
      "* We are a designated EDIH (providing fully discounted services)\n",
      "* We build partnerships and consortiums using our EU wide network\n",
      "* We are not-for-profit\n",
      "\n",
      "Find out more using the links below or contact us [**here**](https://ceadar.ie/latest-news-events/#get-in-touch)\n",
      "\n",
      "#### [Who We Are](https://ceadar.ie/who-we-are)\n",
      "\n",
      "[Learn more](https://ceadar.ie/who-we-are)\n",
      "\n",
      "#### [Our Services](https://ceadar.ie/services)\n",
      "\n",
      "[Learn more](https://ceadar.ie/services)\n",
      "\n",
      "#### [Projects](https://ceadar.ie/projects)\n",
      "\n",
      "[Learn more](https://ceadar.ie/projects)\n",
      "\n",
      "## CeADARâ€™s European Digital Innovation Hub (EDIH) for AI Programme\n",
      "\n",
      "We support Enterprises with under 3,000 staff and Public Service Organisations in Ireland to understand and use data analytics and AI to empower their business/organisation. All our EDIH for AI Programme services are 100% discounted.\n",
      "\n",
      "[Find Out More](https://ceadar.ie/edih)\n",
      "\n",
      "## Who Weâ€™ve Worked With\n",
      "\n",
      "## CeADARâ€™s AI NewsHub\n",
      "\n",
      "#### Access the latest in AI news from across the world and stay ahead of the curve\n",
      "\n",
      "[Visit AI NewsHub](https://ainewshub.ie/)\n",
      "\n",
      "## Recognition & Awards\n",
      "\n",
      "### 2024\n",
      "\n",
      "Winner\n",
      "\n",
      "### 2023\n",
      "\n",
      "Finalist\n",
      "\n",
      "### 2023\n",
      "\n",
      "Awarded\n",
      "\n",
      "### 2022\n",
      "\n",
      "Awarded\n",
      "\n",
      "### 2021\n",
      "\n",
      "Finalist\n",
      "\n",
      "### 2019\n",
      "\n",
      "Project Winner\n",
      "\n",
      "## CeADAR Membership\n",
      "\n",
      "[View Membership Details](https://ceadar.ie/membership/)\n",
      "\n",
      " </raw></document>\n",
      "<document><title>CeADAR Ireland - LinkedIn</title><url>https://ie.linkedin.com/company/ceadar-ireland</url><content>Overview:\\nCeADAR is Ireland's National Centre for AI. Funded by EI and the IDA, CeADAR has more than 90 member companies across a wide span of industries and is one of 30 Digital Innovation Hubs across the EU focused on delivering AI services to industry. CeADAR is hosted at University College Dublin. The primary work of the Centre is on cutting-edge applied research and developing and deploying industry prototypes and solutions to companies. Our catalogue of industry prototypes of AI and analytics tools are all available at no charge for member companies to evaluate on premises. CeADAR also helps its member companies benchmark their state of AI capacity and we work with companies to map out their AI strategy roadmaps. CeADAR is also very active in European funded projects, spinouts, industry upskilling and has its own high-performance computing infrastructure.\\n\\nWebsite: https://ceadar.ie/\\nCrunchbase Url: https://www.crunchbase.com/organization/ceadar-centre-for-applied-data-analytics-research?utm_source=linkedin&utm_medium=referral&utm_campaign=linkedin_companies&utm_content=profile_cta_anon&trk=funding_crunchbase\\nLinkedin Url: https://www.linkedin.com/company/ceadar-ireland\\n\\nIndustry:\\nResearch Services\\n\\nCompany size:\\n51-200 employees\\n90 associated members (LinkedIn members whoâ€™ve listed CeADAR Ireland as their current workplace on their profile)\\n\\nFounded:\\n2012\\n\\nFunding:\\nLast Round Date: 2020-07-11T00:00:00.000Z\\nLast Round Type: Grant\\nTotal Rounds: 3\\nLast Round Raised: US$ 278.8K\\n\\nInvestors:\\nEnterprise Ireland</content><raw># CeADAR Ireland\n",
      "Irelandâ€™s National Centre for Applied AI\n",
      "Research Services â€¢ Dublin â€¢ 6,856 followers â€¢ 51-200 employees\n",
      "\n",
      "## Overview\n",
      "CeADAR is Ireland's National Centre for AI. Funded by EI and the IDA, CeADAR has more than 90 member companies across a wide span of industries and is one of 30 Digital Innovation Hubs across the EU focused on delivering AI services to industry. CeADAR is hosted at University College Dublin. The primary work of the Centre is on cutting-edge applied research and developing and deploying industry prototypes and solutions to companies. Our catalogue of industry prototypes of AI and analytics tools are all available at no charge for member companies to evaluate on premises. CeADAR also helps its member companies benchmark their state of AI capacity and we work with companies to map out their AI strategy roadmaps. CeADAR is also very active in European funded projects, spinouts, industry upskilling and has its own high-performance computing infrastructure.\n",
      "\n",
      "### Website\n",
      "[https://ceadar.ie/](https://ceadar.ie/)\n",
      "### Crunchbase\n",
      "[https://www.crunchbase.com/organization/ceadar-centre-for-applied-data-analytics-research?utm_source=linkedin&utm_medium=referral&utm_campaign=linkedin_companies&utm_content=profile_cta_anon&trk=funding_crunchbase](https://www.crunchbase.com/organization/ceadar-centre-for-applied-data-analytics-research?utm_source=linkedin&utm_medium=referral&utm_campaign=linkedin_companies&utm_content=profile_cta_anon&trk=funding_crunchbase)\n",
      "### LinkedIn\n",
      "[https://www.linkedin.com/company/ceadar-ireland](https://www.linkedin.com/company/ceadar-ireland)\n",
      "\n",
      "### Industry\n",
      "Research Services\n",
      "\n",
      "### Company Size\n",
      "51-200 employees  \n",
      "90 associated members (LinkedIn members who've listed CeADAR Ireland as their current workplace on their profile)\n",
      "\n",
      "### Founded\n",
      "2012\n",
      "\n",
      "### Funding\n",
      "**Last Round Date:** 2020-07-11T00:00:00.000Z\n",
      "**Last Round Type:** Grant\n",
      "**Total Rounds:** 3\n",
      "**Last Round Raised:** US$ 278.8K\n",
      "\n",
      "### Investors\n",
      "Enterprise Ireland\n",
      "\n",
      "### Specialties\n",
      "Data Analytics, Machine Learning, Deep Learning, Intelligent Analytic Interfaces, Data Management for Analytics, AI, Predictive Analytics, and Applied AI\n",
      "\n",
      "## Locations\n",
      "Nexus UCD, Block 9/10, Belfield Office Park, Clonskeagh, Dublin, D04 V2N9, IE\n",
      "\n",
      "### Get Directions\n",
      "[Directions](https://www.bing.com/maps?where=Nexus+UCD%2C+Block+9%2F10%2C++Belfield+Office+Park+Clonskeagh+Dublin+D04+V2N9+IE&trk=org-locations_url)\n",
      "\n",
      "## Employees\n",
      "**Edward McDonnell** (N/A): [https://ie.linkedin.com/in/edmcdonnell?trk=org-employees](https://ie.linkedin.com/in/edmcdonnell?trk=org-employees); **Dr. Anthony Bolton** (N/A): [https://ie.linkedin.com/in/anthonybolton?trk=org-employees](https://ie.linkedin.com/in/anthonybolton?trk=org-employees); **Luca Longo** (N/A): [https://ie.linkedin.com/in/drlucalongo?trk=org-employees](https://ie.linkedin.com/in/drlucalongo?trk=org-employees); **Keelin Murphy** (N/A): [https://ie.linkedin.com/in/keelinmurphy?trk=org-employees](https://ie.linkedin.com/in/keelinmurphy?trk=org-employees)\n",
      "\n",
      "## Similar Companies\n",
      "**Orcawise** (Business Consulting and Services): [https://ie.linkedin.com/company/orcawise?trk=similar-pages](https://ie.linkedin.com/company/orcawise?trk=similar-pages) (Dublin, Europe); **NovaUCD** (Research Services): [https://ie.linkedin.com/company/novaucd?trk=similar-pages](https://ie.linkedin.com/company/novaucd?trk=similar-pages) (Belfield , Dublin); **Enterprise Ireland** (International Trade and Development): [https://ie.linkedin.com/company/enterprise-ireland?trk=similar-pages](https://ie.linkedin.com/company/enterprise-ireland?trk=similar-pages) (N/A); **WiSAR Lab and Technology Gateway** (Research Services): [https://ie.linkedin.com/company/wisar-lab?trk=similar-pages](https://ie.linkedin.com/company/wisar-lab?trk=similar-pages) (N/A); **Skippio** (Technology, Information and Internet): [https://www.linkedin.com/company/skippio-limited?trk=similar-pages](https://www.linkedin.com/company/skippio-limited?trk=similar-pages) (N/A); **Insight Research Ireland Centre for Data Analytics** (Research Services): [https://ie.linkedin.com/company/insight-centre-for-data-analytics?trk=similar-pages](https://ie.linkedin.com/company/insight-centre-for-data-analytics?trk=similar-pages) (Ireland, Ireland); **AI Ireland** (Technology, Information and Media): [https://ie.linkedin.com/company/aiawardsirl?trk=similar-pages](https://ie.linkedin.com/company/aiawardsirl?trk=similar-pages) (Dublin 8, Dublin); **AIB** (Banking): [https://ie.linkedin.com/company/aibireland?trk=similar-pages](https://ie.linkedin.com/company/aibireland?trk=similar-pages) (Molesworth Street , Dublin 2); **Strata** (Engineering Services): [https://ie.linkedin.com/company/strataengineering?trk=similar-pages](https://ie.linkedin.com/company/strataengineering?trk=similar-pages) (N/A); **AI2Peat / PeatSense** (Technology, Information and Internet): [https://ie.linkedin.com/company/ai2peat?trk=similar-pages](https://ie.linkedin.com/company/ai2peat?trk=similar-pages) (N/A)\n",
      "\n",
      "## Posts\n",
      "**CeADAR Ireland** (4d Edited): âœ¨ Last month, CeADAR Ireland , in partnership with Enterprise Europe Network - Ireland , hosted â€œAccelerating Growth Through AI Adoptionâ€ in Dublin, where an audience of start-ups, SMEs and public sector organisations explored practical pathways to digitalisation and heard directly from companies and PSOs already benefiting from CeADARâ€™s EDIH for AI programme. Read more in the Irish Independent https://lnkd.in/eGWMaPkt Enterprise Ireland European Commission European Digital Innovation Hubs Network [Likes: 25, Comments: 0]; **CeADAR Ireland** (4d 1w Edited): ğŸŒŠ Blue Bridge: Connecting ADT4Blue OC3 Applicants Join the ADT4Blue - Advanced Digital Technologies for the Blue Economy OC3 Matchmaking Session â€“ the ultimate space where tech innovators, entrepreneurs, SMEs, startups, researchers, Blue Economy visionaries, students, and alumni come together to spark powerful new collaborations. Details to register below. CeADAR Ireland is a project partner on ADT4Blue. [Likes: 3, Comments: 0]; **CeADAR Ireland** (1w): ğ—ªğ—²ğ—¯ğ—¶ğ—»ğ—®ğ—¿ ğ—¥ğ—²ğ—°ğ—¼ğ—¿ğ—±ğ—¶ğ—»ğ—´ - ğ—§ğ—µğ—² ğ—”ğ—¿ğ˜ ğ—¼ğ—³ ğ—£ğ—¼ğ˜€ğ˜€ğ—¶ğ—¯ğ—¹ğ—² ğ˜„ğ—¶ğ˜ğ—µ ğ—šğ—²ğ—»ğ—²ğ—¿ğ—®ğ˜ğ—¶ğ˜ƒğ—² ğ—”ğ—œ: ğ—¨ğ—»ğ—¹ğ—¼ğ—°ğ—¸ğ—¶ğ—»ğ—´ ğ—£ğ—¿ğ—¼ğ—±ğ˜‚ğ—°ğ˜ğ—¶ğ˜ƒğ—¶ğ˜ğ˜† ğ—®ğ—»ğ—± ğ—¦ğ˜ğ—¿ğ—®ğ˜ğ—²ğ—´ğ—¶ğ—° ğ—”ğ—±ğ˜ƒğ—®ğ—»ğ˜ğ—®ğ—´ğ—² ğ˜„ğ—¶ğ˜ğ—µ ğ—£ğ—²ğ—¿ğ—½ğ—¹ğ—²ğ˜…ğ—¶ğ˜ğ˜† ğ—”ğ—œ In case you missed it, you can now access the recording of our latest webinar on YouTube, where we discuss some of Perplexity AIâ€™s most practical use cases. â¡ï¸ https://lnkd.in/eUpQWWAu This webinar recording will help you: ğŸ”¹Get familiar with Perplexityâ€™s UI & best practices Navigate basic interface elements, understand sources & citations, learn how threads work and get a clearer understanding for what differentiates Perplexity AI from other LLMs. ğŸ”¹Understand how to connect your tools to boost efficiency Combine docs, web, and CRM data to auto-summarise meetings, generate reports, and prioritise your tasks. ğŸ”¹Stay informed with Daily Digest Auto-scrape selected pages for news, trends, and competitors; get concise, styled updates in your inbox. ğŸ”¹Run balanced evaluations end-to-end Merge web search, document analysis, and app connectors to assess vendors/risks. e.g., upload contracts, pull reviews/regulation, and produce executive summary reports, collating RFP data and presenting you with ranked recommendations. #WebinarRecording #PerplexityAI #CeADAR #AI #GenerativeAI #DigitalInnovation #LLMs #Automation #AIProductivity [Likes: 8, Comments: 0]; **CeADAR Ireland** (1w Edited): A wide-ranging exploration of AI from CeADAR Ireland , Insight Research Ireland Centre for Data Analytics and ADAPT Centre at today's Chamber of Intelligence: An AI Showcase event in the University College Dublin â€™s Fitzgerald Debating Chamber. CeADAR Ireland showcased projects including AI2Peat / PeatSense , Corrado Grappiolo, PhD , MANOLO Project , Ricardo Simon Carbajo and PeRCEPTION, AndrÃ©s L. SuÃ¡rez-Cetrulo, PhD . Thank you to all the speakers and attendees and to Marguerite Barry of UCD, Prof Barry O'Sullivan of UCC and Prof Alan Smeaton of DCU for the lively panel discussion and to CeADAR CEO John Lonsdale for his closing remarks. Brian Mac Namee , Olivia Waters , Donnacha O'Driscoll , #AI #AIShowcase #researchcollaboration #AIEcosystem #IrishResearch [Likes: 54, Comments: 1]; **CeADAR Ireland** (1w): â€œğ—ªğ—²â€™ğ˜ƒğ—² ğ—²ğ—»ğ—´ğ—®ğ—´ğ—²ğ—± ğ˜„ğ—¶ğ˜ğ—µ ğ—–ğ—²ğ—”ğ——ğ—”ğ—¥ ğ—³ğ—¼ğ—¿ ğ—¼ğ˜ƒğ—²ğ—¿ ğ—® ğ˜†ğ—²ğ—®ğ—¿ ğ—»ğ—¼ğ˜„ ğ—®ğ—»ğ—± ğ˜„ğ—²â€™ğ˜ƒğ—² ğ—µğ—®ğ—± ğ—® ğ—¿ğ—²ğ—®ğ—¹ğ—¹ğ˜† ğ—³ğ—®ğ—»ğ˜ğ—®ğ˜€ğ˜ğ—¶ğ—° ğ—²ğ˜…ğ—½ğ—²ğ—¿ğ—¶ğ—²ğ—»ğ—°ğ—²â€. Ciara Garvan , WorkJuggle . This monthâ€™s event, Accelerating Growth Through AI Adoption, was an opportunity to hear firsthand from founders like Ciara who have availed of CeADARâ€™s 100% funded EDIH for AI services, targeted at growing the digital capabilities of SMEs and public sector organisations across Ireland. â€œEvents like today are really helpful for SMEs because they give them an opportunity to see how other people are using AI to transform their businesses, and they get to hear how CeADAR can help them every step of the wayâ€ Jean Carberry , Department of Enterprise, Tourism and Employment Special thank you to Jean Carberry, Department of Enterprise, Tourism and Employment, Ciara Garvan, WorkJuggle, Louise MacAvin , SOLAS (An tSeirbhÃ­s Oideachais LeanÃºnaigh agus Scileanna) and James Leigh , R&D Tax Solutions for taking the time out to chat to us at the event last week. Follow us on LinkedIn and sign up for our newsletter for all the latest news and upcoming events. https://ceadar.ie/edih European Digital Innovation Hubs Network Enterprise Ireland European Commission Data2Sustain ENTIRE EDIH Ireland Advancing Innovation in Manufacturing (AIM) Centre #AI #DigitalInnovation #Funding #SMEs #PublicSector #CeADAR #EnterpriseEuropeNetwork #EnterpriseIreland #BetterPublicServices #DigitalEurope [Likes: 20, Comments: 0]; **CeADAR Ireland** (2w): Sign up for our upcoming webinar and learn a simple, repeatable way to use Perplexity AI to streamline workflows, stay informed, and run end-to-end vendor evaluations, no coding required. â¡ï¸ https://lnkd.in/eiDcqcdX In this practical session, you will learn how to: âœ… Get productive with Perplexityâ€™s UI & best practices Navigate Spaces, switch models and modes, use Focus/Pro Search, upload files, craft clear prompts, save to Collections, and verify via source citations. âœ… Connect your tools to boost efficiency Combine docs, web, and CRM data to auto-summarise meetings, generate reports, and prioritise tasks less context-switching, more output. âœ… Stay informed with Daily Digest Auto-scrape selected pages for news, trends, and competitors; get concise, styled updates in your inbox. âœ… Run balanced evaluations end-to-end Merge web search, document analysis, and app connectors to assess vendors/risks. e.g., upload contracts, pull reviews/regulation, and produce an actionable pros/cons report tailored to your use case. This webinar is fully funded, supported by the European Digital Innovation Hubs Network for AI programme, funded by Enterprise Ireland and the European Commission . [Likes: 19, Comments: 0]; **CeADAR Ireland** (2w 2w): ğŸ’¡ Pathways for AI Projects - There's still time to sign up! Join us today from 5â€“7pm for an online webinar hosted by TechIreland. Enterprise Ireland European Digital Innovation Hubs Network [Likes: 5, Comments: 0]; **CeADAR Ireland** (2w): Join us on Tuesday 25th November for Chamber of Intelligence: An AI Showcase. Discover case studies grounded in solid research and real-world need. This event will connect researchers, innovators, and industry partners who are working at the cutting edge of AI. CeADAR Ireland , Insight Research Ireland Centre for Data Analytics , and ADAPT Centre will celebrate the impactful research taking place across the three centres, the powerful partnerships with industry and public bodies, and the innovative spirit of the AI research community. Guests will hear first-hand accounts of AI research in action, exploring the stories, shared challenges and lessons learned. Together, these experiences will highlight the positive change that the research is driving across society. Hosted by University College Dublin in the distinctive Fitzgerald Debating Chamber, the event invites active participation, lively debate, and opportunities to connect with researchers and peers while exploring practical and responsible applications of AI. Register here: https://lnkd.in/edtTuZv8 Details: Tue 25 Nov 2025 10:00 - 14:00 GMT | Fitzgerald Debating Chamber, University College Dublin (UCD) John Lonsdale , Ricardo Simon Carbajo , Corrado Grappiolo, PhD , Laura Plunkett , AndrÃ©s L. SuÃ¡rez-Cetrulo, PhD , Linda Henriksson , Olivia Waters , Daphne Hosford , Edmond O'Connor , Brian Mac Namee , Barry O'Sullivan , UCD Research , NovaUCD , European Digital Innovation Hubs Network , Enterprise Ireland Research Ireland [Likes: 26, Comments: 0]; **CeADAR Ireland** (2w): Highlights from last Thursdayâ€™s event, Accelerating Growth through AI Adoption, hosted in partnership with Enterprise Europe Network - Ireland Thank you to everyone who attended and for taking the opportunity to share your takeaways and learnings from what was a fantastic morning of networking and knowledge sharing. We hope you enjoyed the day, and that you were able to walk away with a clearer understanding of CeADARâ€™s EDIH for AI programme and the wide range of 100% funded services available. If you would like to keep up to date with the latest news and events hosted by CeADARâ€™s EDIH for AI or find out more about the services available complete our contact form: https://lnkd.in/eM4X_uSE View more photos from the event here: https://lnkd.in/eBUT5sCN Thank you again to our panelists, speakers, and organisers for helping make the day such a success. We look forward to seeing you again soon at our next event. European Digital Innovation Hubs Network Enterprise Ireland European Commission Data2Sustain ENTIRE EDIH Ireland Advancing Innovation in Manufacturing (AIM) Centre #AI #DigitalInnovation #Funding #SMEs #PublicSector #CeADAR #EnterpriseEuropeNetwork #EnterpriseIreland #BetterPublicServices #DigitalEurope [Likes: 53, Comments: 1]; **CeADAR Ireland** (3w Edited): Yesterday CeADAR, the European Digital Innovation Hub (EDIH) for AI hosted an informative event in partnership with Enterprise Europe Network - Ireland . The event showcased Irish SMEs and public sector organisations (PSOs) who have engaged with CeADARâ€™s EDIH programme to accelerate their growth by adopting AI technology. Weâ€™d like to thank our event partners Enterprise Europe Network and all our speakers, moderators, organisers and attendees who helped make the event so successful. It was a fantastic day spent showcasing the success stories of companies and organisations and their real-world applications of CeADARâ€™s EDIH for AI programme, as well as a chance to gain insight from a wide array of talented industry professionals. John Lonsdale , CEO of CeADAR welcomed everyone to the event with an insightful look at the benefits and challenges of AI adoption for business. In the opening remarks Anne Lanigan , Divisional Manager of Technology and Services at Enterprise Ireland , emphasised the relevance of AI to Enterprise Irelandâ€™s Scaling agenda and the importance of collaboration across Europe with the significant support of EEN and the EDIH Network. Jean Carberry , Assistant Secretary for Digital Policy at the Department of Enterprise, Tourism and Employment , provided the strategic and policy context, linking Irelandâ€™s national AI and digitalisation agenda with delivery through EI, EEN and the EDIH Network. Ricardo Simon Carbajo , CeADARâ€™s Director of Innovation & Development, introduced the EDIH for AI programme and gave context to the panel discussions that followed. The panel discussions highlighted how accessible the EDIH for AI programme is for all types and size of enterprise and organisation with panellists emphasising the high level of support and expertise available through the programme, which enabled them to experiment, learn and move forward confidently in applying AI solutions to their business stressors. Click here to read more, including a full list of speakers and panellists - https://bit.ly/49TIYhz Click here to contact us and start your digital and AI transformation journey - https://lnkd.in/eM4X_uSE Thank you to our panelists, moderators and speakers: Laura Plunkett , Ramy Ebeid , JP Rooney , Carol O'Toole Boon, Stephen Hartnett, Ciara Garvan , Shane Cradock , Lee Bristow , Yuxin Wang , Niall Dennehy, Donal Kerr , Johnny Dunne , Julie Dowling , Stephen Barnes , Mike Conroy , Patrick Sweeney, Jacqueline Hunt, Paul Browne and Liam Cronin European Digital Innovation Hubs Network Enterprise Ireland European Commission Data2Sustain ENTIRE EDIH Ireland #AI #DigitalInnovation #SMEs #CeADAR #EnterpriseEuropeNetwork #EnterpriseIreland [Likes: 98, Comments: 2]\n",
      "\n",
      "## Media\n",
      "- **Images:** https://media.licdn.com/dms/image/v2/D4E3DAQGsi8LRCVzl5Q/image-scale_191_1128/image-scale_191_1128/0/1716462796301/ceadar_ireland_cover?e=2147483647&v=beta&t=hnSEwkqLgWAZGX4P62nGaIyhyPUtaTBAatIuEkwccIM\n",
      "- **Logo:** ![Company Logo](https://media.licdn.com/dms/image/v2/D560BAQGRXWBlSwUhJg/company-logo_200_200/company-logo_200_200/0/1706704897817/ceadar_ireland_logo?e=2147483647&v=beta&t=8kCwNttxsaeM2oB9Vwf2ZnTXw37268BUS0MwB_cBArw)\n",
      "\n",
      "## Additional  \n",
      "Additional jobs info: Analyst (694,057 open jobs). Biostatistician (21,103 open jobs). Scientist (48,969 open jobs). Consultant (760,907 open jobs). Digital Marketing Specialist (33,650 open jobs). Manager (1,880,925 open jobs). Engineer (555,845 open jobs). Project Manager (253,048 open jobs). Lead Scientist (14,164 open jobs). Head of Analytics (3,468 open jobs). Developer (258,935 open jobs). Data Manager (114,435 open jobs). Manufacturing Intern (1,662 open jobs). Intern (71,196 open jobs). Account Manager (121,519 open jobs). Director (1,220,357 open jobs). Support Engineer (294,729 open jobs). Full Stack Engineer (38,546 open jobs). Data Architect (68,774 open jobs). Information Technology Technician (12,212 open jobs)</raw></document>\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mllm_answer\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32manswer\u001b[0m:\n",
      "CeADAR is Irelandâ€™s national centre for applied AI, headquartered at University College Dublin. It is a market-focused, not-for-profit technology centre that drives accelerated research, development, and deployment of AI, machine learning, and data analytics innovations into businesses. CeADAR supports start-ups, SMEs, and large organizations in adopting AI by providing AI strategies, prototypes, proofs of concept, market-ready solutions, training programs, funding support, and ecosystem networking. It also operates as a European Digital Innovation Hub (EDIH) offering fully discounted AI services to enterprises with under 3,000 staff and public sector organizations in Ireland. CeADAR maintains an extensive catalogue of technology demonstrators and hosts events to foster a thriving data analytics ecosystem.\n",
      "\n",
      "**Source**  \n",
      "- https://ceadar.ie/ (multiple pages)  \n",
      "- https://humancentered-ai.eu/ceadar/  \n",
      "- https://european-digital-innovation-hubs.ec.europa.eu/edih-catalogue/ceadar-irelands-centre-applied-ai  \n",
      "- https://ie.linkedin.com/company/ceadar-ireland\n",
      "('user', 'What is the CeADAR initiative in Ireland?')\n",
      "('assistant', 'CeADAR is Irelandâ€™s national centre for applied AI, headquartered at University College Dublin. It is a market-focused, not-for-profit technology centre that drives accelerated research, development, and deployment of AI, machine learning, and data analytics innovations into businesses. CeADAR supports start-ups, SMEs, and large organizations in adopting AI by providing AI strategies, prototypes, proofs of concept, market-ready solutions, training programs, funding support, and ecosystem networking. It also operates as a European Digital Innovation Hub (EDIH) offering fully discounted AI services to enterprises with under 3,000 staff and public sector organizations in Ireland. CeADAR maintains an extensive catalogue of technology demonstrators and hosts events to foster a thriving data analytics ecosystem.\\n\\n**Source**  \\n- https://ceadar.ie/ (multiple pages)  \\n- https://humancentered-ai.eu/ceadar/  \\n- https://european-digital-innovation-hubs.ec.europa.eu/edih-catalogue/ceadar-irelands-centre-applied-ai  \\n- https://ie.linkedin.com/company/ceadar-ireland')\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "inputs = GraphState(question=[HumanMessage(content=\"what is CeADAR, Ireland?\")])\n",
    "invoke_graph(app, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6cd9d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mquery_rewrite\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the pass@1 value for QwQ-32B-Preview's AIME 2024?\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mretrieve\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mcontext\u001b[0m:\n",
      "<document><content>pass@1 = 1 / k * Î£ (pi), where pi denotes the correctness of the i-th response. This method provides more reliable performance estimates. For AIME 2024, we also report consensus (majority vote) results (Wang et al., 2022) using 64 samples, denoted as cons@64.\n",
      "\n",
      "1https://aider.chat</content><source>data/Deepseek-r1.pdf</source><page>13</page></document>\n",
      "<document><content>During training, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors. After thousands of RL steps, DeepSeek-R1-Zero exhibits super performance on reasoning benchmarks. For instance, the pass@1 score on AIME 2024 increases from 15.6% to 71.0%, and with</content><source>data/Deepseek-r1.pdf</source><page>4</page></document>\n",
      "<document><content>as the RL training advances. Notably, the average pass@1 score on AIME 2024 shows a significant increase, jumping from an initial 15.6% to an impressive 71.0%, reaching performance levels comparable to OpenAI-o1-0912. This significant improvement highlights the efficacy of our RL algorithm in</content><source>data/Deepseek-r1.pdf</source><page>7</page></document>\n",
      "<document><content>DeepSeek-R1-Distill-Qwen-7B achieves 55.5% on AIME 2024, surpassing QwQ-32B-Preview. Additionally, DeepSeek-R1-Distill-Qwen-32B scores 72.6% on AIME 2024, 94.3% on MATH-500, and 57.2% on LiveCodeBench. These results significantly outperform previous open-source models and are comparable to o1-mini.</content><source>data/Deepseek-r1.pdf</source><page>5</page></document>\n",
      "<document><content>AIME 2024 increases from 15.6% to 71.0%, and with majority voting, the score further improves to 86.7%, matching the performance of OpenAI-o1-0912.</content><source>data/Deepseek-r1.pdf</source><page>4</page></document>\n",
      "<document><content>each step of the search process. Training a fine-grained value model is inherently difficult, which makes it challenging for the model to iteratively improve. While AlphaGoâ€™s core success relied on training a value model to progressively enhance its performance, this principle proves difficult to</content><source>data/Deepseek-r1.pdf</source><page>17</page></document>\n",
      "<document><content>its performance based on official reports. For distilled models, we also compare the open-source model QwQ-32B-Preview (Qwen, 2024a).</content><source>data/Deepseek-r1.pdf</source><page>13</page></document>\n",
      "<document><content>| AIME 2024 (Pass\\@1)             | 16.0                    | 9.3    | 39.2     | 63.6   | 79.2   | 79.8     |      |\n",
      "| Math                            | MATH-500 (Pass\\@1)      | 78.3   | 74.6     | 90.2   | 90.0   | 96.4     | 97.3 |</content><source>data/Deepseek-r1.pdf</source><page>14</page></document>\n",
      "<document><content>we default to pass@ğ‘˜ evaluation (Chen et al., 2021) and report pass@1 using a non-zero temperature. Specifically, we use a sampling temperature of 0.6 and a top-ğ‘ value of 0.95 to generate ğ‘˜ responses (typically between 4 and 64, depending on the test set size) for each question. Pass@1 is then</content><source>data/Deepseek-r1.pdf</source><page>13</page></document>\n",
      "<document><content>- Language Mixing: DeepSeek-R1 is currently optimized for Chinese and English, which may result in language mixing issues when handling queries in other languages. For instance, DeepSeek-R1 might use English for reasoning and responses, even if the query is in a language other than English or</content><source>data/Deepseek-r1.pdf</source><page>17</page></document>\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mrelevance_check\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mrelevance\u001b[0m:\n",
      "yes\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mllm_answer\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32manswer\u001b[0m:\n",
      "The pass@1 value for QwQ-32B-Preview on AIME 2024 is 39.2%.\n",
      "\n",
      "**Source:**\n",
      "- data/Deepseek-r1.pdf (page 14)\n",
      "('user', \"What is the pass@1 value for QwQ-32B-Preview's AIME 2024?\")\n",
      "('assistant', 'The pass@1 value for QwQ-32B-Preview on AIME 2024 is 39.2%.\\n\\n**Source:**\\n- data/Deepseek-r1.pdf (page 14)')\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "inputs = GraphState(question=[HumanMessage(content=\"What is value of QwQ-32B-Preview's AIME 2024 pass@1?\")])\n",
    "invoke_graph(app, inputs, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc87d16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mquery_rewrite\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "In what ways does DeepSeek-R1-Zero implement reinforcement learning techniques?\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mretrieve\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mcontext\u001b[0m:\n",
      "<document><content>In this work, we share our journey in enhancing model reasoning abilities through reinforcement learning. DeepSeek-R1-Zero represents a pure RL approach without relying on cold-start data, achieving strong performance across various tasks. DeepSeek-R1 is more powerful, leveraging cold-start data</content><source>data/Deepseek-r1.pdf</source><page>17</page></document>\n",
      "<document><content>After fine-tuning DeepSeek-V3-Base on the cold start data, we apply the same large-scale reinforcement learning training process as employed in DeepSeek-R1-Zero. This phase focuses on enhancing the modelâ€™s reasoning capabilities, particularly in reasoning-intensive tasks such as coding,</content><source>data/Deepseek-r1.pdf</source><page>11</page></document>\n",
      "<document><content>We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL,</content><source>data/Deepseek-r1.pdf</source><page>2</page></document>\n",
      "<document><content>During training, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors. After thousands of RL steps, DeepSeek-R1-Zero exhibits super performance on reasoning benchmarks. For instance, the pass@1 score on AIME 2024 increases from 15.6% to 71.0%, and with</content><source>data/Deepseek-r1.pdf</source><page>4</page></document>\n",
      "<document><content>enhances DeepSeek-R1-Zeroâ€™s reasoning capabilities, enabling it to tackle more challenging tasks with greater efficiency and accuracy.</content><source>data/Deepseek-r1.pdf</source><page>9</page></document>\n",
      "<document><content>Figure 3 | The average response length of DeepSeek-R1-Zero on the training set during the RL process. DeepSeek-R1-Zero naturally learns to solve reasoning tasks with more thinking time.</content><source>data/Deepseek-r1.pdf</source><page>9</page></document>\n",
      "<document><content>In this section, we explore the potential of LLMs to develop reasoning capabilities without any supervised data, focusing on their self-evolution through a pure reinforcement learning process. We start with a brief overview of our RL algorithm, followed by the presentation of some exciting results,</content><source>data/Deepseek-r1.pdf</source><page>6</page></document>\n",
      "<document><content>In this paper, we take the first step toward improving language model reasoning capabilities using pure reinforcement learning (RL). Our goal is to explore the potential of LLMs to develop reasoning capabilities without any supervised data, focusing on their self-evolution through a pure RL</content><source>data/Deepseek-r1.pdf</source><page>4</page></document>\n",
      "<document><content>DeepSeek-R1-Zero demonstrates capabilities such as self-verification, reflection, and generating long CoTs, marking a significant milestone for the research community. Notably, it is the first open research to validate that reasoning capabilities of LLMs can be incentivized purely through RL,</content><source>data/Deepseek-r1.pdf</source><page>5</page></document>\n",
      "<document><content># 4.2. Unsuccessful Attempts\n",
      "\n",
      "In the early stages of developing DeepSeek-R1, we also encountered failures and setbacks along the way. We share our failure experiences here to provide insights, but this does not imply that these approaches are incapable of developing effective reasoning models.</content><source>data/Deepseek-r1.pdf</source><page>16</page></document>\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mrelevance_check\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32mrelevance\u001b[0m:\n",
      "yes\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mllm_answer\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\u001b[1;32manswer\u001b[0m:\n",
      "DeepSeek-R1-Zero implements reinforcement learning (RL) techniques by training purely through large-scale RL without any supervised fine-tuning or cold-start data. It focuses on self-evolution, enabling the model to develop reasoning capabilities such as self-verification, reflection, and generating long chains of thought (CoTs). The RL process involves thousands of steps, during which the model naturally learns to solve reasoning tasks with increased thinking time, significantly improving performance on reasoning benchmarks.\n",
      "\n",
      "**Source:**\n",
      "- data/Deepseek-r1.pdf (pages 2, 4, 5, 6, 9, 17)\n",
      "('user', 'In what ways does DeepSeek-R1-Zero implement reinforcement learning techniques?')\n",
      "('assistant', 'DeepSeek-R1-Zero implements reinforcement learning (RL) techniques by training purely through large-scale RL without any supervised fine-tuning or cold-start data. It focuses on self-evolution, enabling the model to develop reasoning capabilities such as self-verification, reflection, and generating long chains of thought (CoTs). The RL process involves thousands of steps, during which the model naturally learns to solve reasoning tasks with increased thinking time, significantly improving performance on reasoning benchmarks.\\n\\n**Source:**\\n- data/Deepseek-r1.pdf (pages 2, 4, 5, 6, 9, 17)')\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "inputs = GraphState(question=[HumanMessage(content=\"How does DeepSeek-R1-Zero use reinforcement learning?\")])\n",
    "invoke_graph(app, inputs, config[\"query_rewrite\", \"llm_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "005406e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = app.get_state(config).values\n",
    "# outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23034810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
